\documentclass[a4paper,11pt,ja=standard,xelatex]{bxjsreport}

\usepackage{geometry}
\geometry{top=25mm,bottom=25mm,left=25mm,right=25mm}
\usepackage{fontspec}
\usepackage{xeCJK}
\setmainfont{Times New Roman}
\setsansfont{Helvetica}
\setCJKmainfont[
  Path=fonts/ipaex/ipaex/,
  UprightFont=ipaexm.ttf,
  BoldFont=ipamp.ttf,
  Extension=.ttf
]{ipaexm.ttf}
\setCJKsansfont[
  Path=fonts/ipaex/ipaex/,
  UprightFont=ipaexg.ttf,
  BoldFont=ipaexg.ttf,
  Extension=.ttf
]{ipaexg.ttf}
\setCJKmonofont[
  Path=fonts/ipaex/ipaex/,
  UprightFont=ipag.ttf,
  Extension=.ttf
]{ipag.ttf}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[subrefformat=parens]{subcaption}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{float}
\usepackage{comment}
\usepackage{url}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\theoremstyle{definition}
\newtheorem{theorem}{定理}
\renewcommand{\proofname}{\textbf{証明}}

\setcounter{tocdepth}{3}
\setcounter{page}{-1}
\setlength{\parskip}{0em}
\setlength{\topsep}{0em}

\title{意思決定重視学習を用いた制約付き平均--分散ポートフォリオ最適化}
\author{野坂 健成}
\date{\today}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\pagenumbering{roman}
\tableofcontents
\listoffigures
\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\chapter{序論}
\section{研究背景}
\par
金融市場における資産運用では，複数の投資対象に対して資金をどのように配分するかを決定するポートフォリオ最適化問題が中心的な役割を果たしてきた．とりわけ，リスクとリターンのトレードオフを明示的に扱う平均--分散モデル（Mean--Variance Optimization; MVO）は，理論的な明快さと実務的な解釈の容易さから，現在に至るまで広く用いられている．
\par
近年では，機械学習手法の発展に伴い，将来の資産リターンをデータ駆動的に予測し，その予測結果を用いてポートフォリオ最適化を行う枠組みが一般的となっている．このようなアプローチでは，まず過去データから予測モデルを学習し，次に得られた予測値を最適化問題に入力するという\textbf{二段階法（predict-then-optimize; PTO）}の構造が採られることが多い．
\par
しかしながら，ポートフォリオ最適化問題は予測誤差に対して極めて敏感であることが知られており，期待リターンのわずかな推定誤差が投資配分を大きく変化させ，結果として投資成績の悪化を招く可能性がある．特に，実務において想定される小標本・低SNR環境や，売買制約・非負制約などを含む現実的な制約付き問題では，この問題がより顕在化する．
\par
このような背景のもと，予測精度そのものではなく，最終的に得られる意思決定の質に着目した新たな学習パラダイムが注目を集めている．

\section{問題設定}
\par
従来の PTO 型の枠組みでは，期待リターンの予測モデルは主として平均二乗誤差（MSE）などの予測誤差の最小化を目的として学習される．しかし，この学習目標は，必ずしもポートフォリオ最適化問題における投資成績の向上と一致するとは限らない．
\par
ポートフォリオ最適化において重要なのは，予測値そのものの精度ではなく，予測値に基づいて導かれる投資配分が，どれだけ望ましい意思決定を実現するかである．すなわち，予測誤差が小さいにもかかわらず，投資成績が劣化するケースや，逆に予測誤差は大きいが投資判断としては優れているケースが存在し得る．
\par
このギャップは，予測問題と最適化問題を独立に扱う二段階構造そのものに起因していると考えられる．そこで本研究では，意思決定の質を直接的に最適化対象とする学習手法に着目する．
\par
近年提案されている Decision-Focused Learning（DFL）は，予測モデルの学習段階において，下流の最適化問題を明示的に考慮し，最終的な意思決定誤差を最小化することを目的とする枠組みである．ポートフォリオ最適化問題は明確な目的関数と制約構造を持つため，DFL との親和性が高いと考えられる．
\par
本研究では，DFL の枠組みを制約付き平均--分散ポートフォリオ最適化問題に適用し，従来の PTO 手法と比較して，より良い投資判断が実現されるかを検証する．特に，実務を想定した制約条件を明示的に考慮した設定のもとで，DFL の有効性と課題を明らかにすることを目的とする．

\section{関連研究}
\par
ポートフォリオ最適化に関する研究は，Markowitz による平均--分散理論に端を発し，その後，制約付き最適化やロバスト最適化，推定誤差を考慮した手法など，多岐にわたる拡張が提案されてきた．一方で，期待リターンの推定に関しては，回帰モデルや時系列モデル，近年では機械学習を用いた手法が広く用いられている．
\par
従来の多くの研究では，予測モデルの学習とポートフォリオ最適化を独立した問題として扱う PTO の枠組みが採用されてきた．しかし，このアプローチの限界を指摘する研究も増えており，予測誤差と最適化結果との非線形な関係が問題視されている．
\par
こうした課題に対して，予測と最適化を統合的に扱う手法として，Integrating Prediction in Optimization（IPO）や Decision-Focused Learning（DFL）が提案されている．特に Butler and Kwon は，平均--分散ポートフォリオ最適化問題に対して予測モデルを統合的に学習する手法を提案し，従来手法との性能差を示した．
\par
さらに近年では，DFL を二段階最適化問題として厳密に定式化し，強双対性条件や KKT 条件を用いて再定式化する研究も進められている．これらの研究は，意思決定誤差を直接最小化するという観点から理論的に魅力的である一方，非凸性や解法の安定性，計算コストといった課題も指摘されている．
\par
本研究は，これらの先行研究を踏まえ，制約付きポートフォリオ最適化という実務的な設定において，DFL の定式化と解法設計が投資判断にどのような影響を与えるかを体系的に検討する点に特徴がある．

\section{本研究の貢献（暫定）}
\par
本研究の主な貢献は以下のとおりである．
\par
第一に，制約付き平均--分散ポートフォリオ最適化問題に対して，Decision-Focused Learning（DFL）の枠組みを適用し，その数理構造を二段階最適化問題として明示的に定式化した点である．既存研究では，制約のない設定や簡略化された問題が多く扱われてきたのに対し，本研究では，非負制約や予算制約を含む実務的な設定を考慮したモデルを構築している．
\par
第二に，強双対性条件および KKT 条件を用いた再定式化により，DFL に基づくポートフォリオ最適化問題を非凸二次計画問題として整理し，異なる再定式化が持つ数値的性質を比較可能な形で提示した点である．これにより，理論的には等価である再定式化が，数値計算上は異なる挙動を示し得ることを明確にし，解法設計や初期化の重要性を示唆する．
\par
第三に，小標本・低SNR環境を想定した数値実験を通じて，意思決定誤差を直接最小化する学習が，従来の PTO 手法と比較して，投資判断の質を改善し得る可能性を検証する点である．特に，予測誤差の最小化と投資成績の最適化が必ずしも一致しない状況において，DFL の有効性を評価する．
\par
最後に，実務を想定した制約付き設定における DFL の適用可能性と限界を整理し，今後の実データ分析や拡張に向けた課題を明確化する点も，本研究の貢献の一つである．

\section{論文構成}
\par
本論文の構成は以下のとおりである．
\par
第1章では，本研究の背景，問題設定，関連研究を整理し，本研究の目的および位置づけを明確にする．
\par
第2章では，平均--分散ポートフォリオ最適化モデルをはじめとする既存手法について概説し，従来の PTO 型アプローチおよび予測統合型手法の特徴と課題を整理する．
\par
第3章では，Decision-Focused Learning の枠組みに基づくポートフォリオ最適化問題を二段階最適化問題として定式化し，強双対性条件および KKT 条件を用いた再定式化を示す．
\par
第4章では，人工データおよび実データを用いた数値実験の設定を説明し，提案手法と既存手法との比較を通じてその特性を評価する．
\par
第5章では，本研究で得られた知見を総括するとともに，今後の課題と展望について述べる．

\chapter{既存手法}
\section{ポートフォリオ最適化モデル}
\par
本研究では，リスクとリターンのトレードオフを明示的に考慮する平均--分散ポートフォリオ最適化モデル（Mean--Variance Optimization; MVO）を基本的な投資判断モデルとして採用する．
\par
資産数を $d$ とし，投資配分ベクトルを
\[
\boldsymbol{w} = (w_1, \dots, w_d)^\top \in \mathbb{R}^d
\]
とする．また，資産リターンの期待値ベクトルを $\boldsymbol{r} \in \mathbb{R}^d$，共分散行列を $\boldsymbol{V} \in \mathbb{S}_{++}^d$ とする．ここで $\mathbb{S}_{++}^d$ は正定値対称行列の集合を表す．
\par
平均--分散モデルに基づくポートフォリオ最適化問題は，目的関数 \eqref{eq:mvo_obj} を最小化し，制約 \eqref{eq:mvo_budget}--\eqref{eq:mvo_nonneg} のもとで投資配分を決定する問題として定式化される．
\begin{subequations}
\label{eq:mvo}
\begin{align}
c(\boldsymbol{w}, \boldsymbol{r})
&= -(1-\delta)\boldsymbol{r}^\top \boldsymbol{w}
+ \frac{\delta}{2}\boldsymbol{w}^\top \boldsymbol{V}\boldsymbol{w},
\label{eq:mvo_obj}\\
\boldsymbol{1}^\top \boldsymbol{w}
&= 1,
\label{eq:mvo_budget}\\
\boldsymbol{w}
&\ge \boldsymbol{0}.
\label{eq:mvo_nonneg}
\end{align}
\end{subequations}
\par
ここで $0 \le \delta \le 1$ はリターン項とリスク項の比重を制御するトレードオフ係数であり，$\delta \to 0$ のときリターン重視，$\delta \to 1$ のときリスク重視の投資配分が得られる．目的関数 $c(\boldsymbol{w}, \boldsymbol{r})$ は，期待リターンの最大化項と分散リスクの最小化項から構成されており，制約集合は予算制約および非負制約を表している．共分散行列 $\boldsymbol{V}$ が正定値である場合，本問題は凸二次計画問題となり，グローバル最適解が一意に定まる．

\subsection{実務における推定問題}
\par
実際の運用においては，期待リターン $\boldsymbol{r}$ および共分散行列 $\boldsymbol{V}$ は未知であり，過去データから推定される．特に期待リターンの推定誤差は，最適化問題 \eqref{eq:mvo} の解に大きな影響を与えることが知られている．
\par
このため，実務では回帰モデルや時系列モデル，近年では機械学習手法を用いてリターンを予測し，その予測値を最適化問題に入力するという枠組みが一般的に用いられている．本稿では，期待リターンの推定値（予測値）を $\hat{\boldsymbol{r}}$ のようにハットを付して表す．

\section{予測統合型の手法}

\subsection{PTO アプローチ}
\par
従来の多くの研究および実務では，予測と最適化を独立した問題として扱う PTO 型のアプローチが採用されてきた．具体的には，特徴量ベクトル $\boldsymbol{x}_i \in \mathbb{R}^d$ に基づいて，資産リターンを次の線形モデルで予測する．
\begin{equation}
\hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)
= \mathrm{diag}(\boldsymbol{x}_i)\boldsymbol{\theta},
\label{eq:prediction_model}
\end{equation}
\par
ここで $\boldsymbol{\theta} \in \mathbb{R}^d$ は回帰係数である．$\boldsymbol{\theta}$ は，次の最小二乗問題を解くことで推定される．
\begin{equation}
\min_{\boldsymbol{\theta}}
\frac{1}{T} \sum_{i=1}^{T}
\left\|
\boldsymbol{r}_i - \hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)
\right\|_2^2.
\label{eq:ols}
\end{equation}
\par
得られた予測値 $\hat{\boldsymbol{r}}_i$ を用いて，ポートフォリオ最適化問題 \eqref{eq:mvo} を解くことで投資配分が決定される．

\subsection{PTO の課題}
\par
PTO アプローチでは，予測モデルの学習目的が \eqref{eq:ols} に示すように予測誤差の最小化である．一方で，最適化問題 \eqref{eq:mvo} における最終的な評価基準は投資成績，すなわち意思決定の質である．
\par
このため，予測誤差の最小化が必ずしも最適な投資判断につながるとは限らない．特に，ポートフォリオ最適化問題では，期待リターンのわずかな推定誤差が投資配分を大きく変化させることがあり，結果として投資成績が不安定になる可能性がある．この問題は，予測と最適化を分離して扱う二段階構造そのものに起因すると考えられる．

\subsection{予測統合型アプローチ（IPO）}
\par
この課題に対して，Butler and Kwon は，予測モデルの学習段階に最適化問題を統合する手法として，Integrating Prediction in Mean--Variance Portfolio Optimization（IPO）を提案した．IPO では，予測モデルのパラメータ $\boldsymbol{\theta}$ を，予測誤差ではなく，予測値に基づいて得られるポートフォリオの目的関数値を通じて更新する．これにより，予測モデルがポートフォリオ最適化問題の構造を直接考慮することが可能となる．
\par
一方で，IPO は非凸最適化問題として定式化されるため，勾配計算の計算量や局所解への収束，数値的安定性といった課題も指摘されている．

\section{本章のまとめ}
\par
本章では，平均--分散ポートフォリオ最適化モデルを基礎として，従来の PTO アプローチおよび予測統合型手法について整理した．次章では，これらの課題を踏まえ，意思決定の質を直接最適化対象とする Decision-Focused Learning に基づくポートフォリオ最適化モデルを提案する．

\chapter{提案手法}
\section{二段階最適化モデル}
\par
本章では，Decision-Focused Learning（DFL）の枠組みに基づき，制約付き平均--分散ポートフォリオ最適化問題を二段階最適化問題として定式化する．本研究では特に，リターン項とリスク項の相対的重要度を明示的に制御するため，トレードオフ係数 $\delta\in[0,1]$ を用いた修正平均--分散モデルを採用する．

\subsection{問題設定と予測モデル}
\par
時点 $i=1,\dots,T$ において，特徴量ベクトル $\boldsymbol{x}_i \in \mathbb{R}^d$ および実現リターン $\boldsymbol{r}_i \in \mathbb{R}^d$ が観測されるとする．期待リターンは，以下の線形単回帰モデルにより予測されるものとする．
\begin{equation}
\hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)
= \mathrm{diag}(\boldsymbol{x}_i)\boldsymbol{\theta},
\label{eq:dfl_prediction_new}
\end{equation}
\par
ここで $\boldsymbol{\theta} \in \mathbb{R}^d$ は学習対象となる回帰係数である．

\subsection{下位問題：制約付きポートフォリオ最適化}
\par
予測モデル \eqref{eq:dfl_prediction_new} に基づき，各時点 $i$ における投資配分（予測に基づく配分）を $\hat{\boldsymbol{w}}_i$ とし，次の制約付き最適化問題の解として定義する．
\begin{equation}
\hat{\boldsymbol{w}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)
\in
\arg\min_{\boldsymbol{w}_i \in \mathcal{S}}
c\!\left(\boldsymbol{w}_i, \hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)\right),
\label{eq:lower_level_new}
\end{equation}
\par
ただし，目的関数は次の修正平均--分散コスト関数で与えられる．
\begin{equation}
c(\boldsymbol{w}_i, \boldsymbol{r})
= -(1-\delta)\boldsymbol{r}^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i,
\quad 0 \le \delta \le 1.
\label{eq:modified_mvo}
\end{equation}
\par
制約集合 $\mathcal{S}$ は
\begin{equation}
\mathcal{S}
= \left\{
\boldsymbol{w}_i \in \mathbb{R}^d
\ \middle|\ 
\boldsymbol{1}^\top \boldsymbol{w}_i = 1,\ 
\boldsymbol{w}_i \ge \boldsymbol{0}
\right\}
\label{eq:feasible_set_new}
\end{equation}
とする．
\par
ここで $\boldsymbol{V}_i \in \mathbb{S}_{++}^d$ は共分散行列であり，$\delta$ はリターン項とリスク項の比重を制御するパラメータである．$\delta \to 0$ のときリターン重視，$\delta \to 1$ のときリスク重視の投資配分が得られる．

\subsection{理想的な投資配分}
\par
意思決定誤差を評価する基準として，各時点 $i$ において実現リターン $\boldsymbol{r}_i$ が既知であると仮定した場合の理想的な投資配分を次のように定義する．
\begin{equation}
\boldsymbol{w}_i^*
\in
\arg\min_{\boldsymbol{w}_i \in \mathcal{S}}
c(\boldsymbol{w}_i, \boldsymbol{r}_i).
\label{eq:ideal_solution_new}
\end{equation}
\par
この投資配分は実運用では利用できないが，DFL における意思決定誤差の評価基準として用いる．

\subsection{上位問題：意思決定誤差最小化}
\par
Decision-Focused Learning では，予測モデルのパラメータ $\boldsymbol{\theta}$ を，予測誤差ではなく意思決定の質を通じて学習する．本研究では，各時点 $i$ における意思決定誤差を次のように定義する．
\begin{equation}
\ell_i(\boldsymbol{\theta})
= c\!\left(\hat{\boldsymbol{w}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i), \boldsymbol{r}_i\right)
- c(\boldsymbol{w}_i^*, \boldsymbol{r}_i).
\label{eq:decision_loss_new}
\end{equation}
\par
このとき，上位問題は次の二段階最適化問題として定式化される．
\begin{subequations}
\label{eq:upper_level_new}
\begin{align}
\min_{\boldsymbol{\theta}} \quad
& \frac{1}{T}\sum_{i=1}^{T} \ell_i(\boldsymbol{\theta}),
\label{eq:upper_level_obj}\\
\text{s.t.} \quad
& \hat{\boldsymbol{w}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)
\ \text{は}\ \eqref{eq:lower_level_new}\ \text{の最適解}.
\label{eq:upper_level_constraint}
\end{align}
\end{subequations}
\par
すなわち，本研究で扱う問題は，制約付き平均--分散ポートフォリオ最適化を下位問題に含む二段階最適化問題である．

\subsection{問題の性質と再定式化への動機}
\par
定式化 \eqref{eq:upper_level_new} は，下位問題に $\arg\min$ 演算子を含むため，直接的な数値計算が困難である．また，下位問題の解を通じて定義される目的関数は一般に非凸となる．
\par
そこで本研究では，下位問題の最適性条件を用いて $\arg\min$ 演算子を除去し，単一レベルの非凸二次計画問題として再定式化する．次節では，\textbf{強双対性条件に基づく定式化（DFL-QCQP-DUAL）および KKT 条件に基づく定式化（DFL-QCQP-KKT）}について詳述する．

\section{再定式化による単一レベル最適化問題}
\par
前節で定式化した二段階最適化問題 \eqref{eq:upper_level_new} は，下位問題に $\arg\min$ 演算子を含むため，直接的な数値計算が困難である．そこで本節では，下位問題の最適性条件を用いて $\arg\min$ 演算子を除去し，単一レベルの最適化問題として再定式化する．本研究では，先行研究に従い，(1) 強双対性条件に基づく再定式化（DFL-QCQP-DUAL），(2) KKT 条件に基づく再定式化（DFL-QCQP-KKT）の2通りの定式化を考える．

\subsection{下位問題のラグランジュ関数}
\par
各時点 $i$ における下位問題 \eqref{eq:lower_level_new} を再掲する．ここでは簡単のため $\hat{\boldsymbol{r}}_i := \hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)$ とおく．
\begin{subequations}
\label{eq:lower_level_recall}
\begin{align}
\min_{\boldsymbol{w}_i \in \mathbb{R}^d} \quad
& -(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i,
\label{eq:lower_level_recall_obj}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\label{eq:lower_level_recall_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0}.
\label{eq:lower_level_recall_nonneg}
\end{align}
\end{subequations}
\par
等式制約および不等式制約に対応するラグランジュ乗数を，それぞれ $\mu_i \in \mathbb{R}$，$\boldsymbol{\lambda}_i \in \mathbb{R}^d_{\ge 0}$ とすると，ラグランジュ関数は次のように与えられる．
\begin{equation}
\begin{aligned}
\mathcal{L}_i(\boldsymbol{w}_i, \mu_i, \boldsymbol{\lambda}_i)
&=
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
+ \mu_i(\boldsymbol{1}^\top \boldsymbol{w}_i - 1)
- \boldsymbol{\lambda}_i^\top \boldsymbol{w}_i.
\end{aligned}
\label{eq:lagrangian}
\end{equation}

\subsection{強双対性条件に基づく再定式化（DFL-QCQP-DUAL）}
\par
下位問題 \eqref{eq:lower_level_recall} は凸二次計画問題であり，スレーター条件が満たされるため，強双対性が成立する．このとき，原問題と双対問題の最適値が一致することから，次の条件が成り立つ．
\begin{equation}
\begin{aligned}
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\le
\mu_i,
\end{aligned}
\label{eq:dual_value}
\end{equation}
\par
さらに，ラグランジュ関数の一階条件より，
\begin{equation}
\delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
=
-\mu_i \boldsymbol{1}
+ \boldsymbol{\lambda}_i.
\label{eq:dual_stationarity}
\end{equation}
\par
以上を用いることで，二段階最適化問題 \eqref{eq:upper_level_new} は，次の単一レベル最適化問題として再定式化される．
\begin{subequations}
\label{eq:dfl_dual}
\begin{align}
\min_{\boldsymbol{\theta}, \{\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i\}_{i=1}^{T}}
\quad
& \frac{1}{T}\sum_{i=1}^{T}
\left(
-(1-\delta)\boldsymbol{r}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\right),
\label{eq:dfl_dual_obj}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\qquad i=1,\dots,T,
\label{eq:dfl_dual_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_dual_nonneg}\\
& \boldsymbol{\lambda}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_dual_lambda_nonneg}\\
& -(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\le \mu_i,
\qquad i=1,\dots,T,
\label{eq:dfl_dual_value}\\
& \delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
= -\mu_i \boldsymbol{1}
+ \boldsymbol{\lambda}_i,
\qquad i=1,\dots,T.
\label{eq:dfl_dual_stationarity}
\end{align}
\end{subequations}
\par
この定式化を DFL-QCQP-DUAL と呼ぶ．

\subsection{KKT 条件に基づく再定式化（DFL-QCQP-KKT）}
\par
別の再定式化として，下位問題 \eqref{eq:lower_level_recall} の KKT 条件をすべて制約として組み込む方法を考える．KKT 条件は以下から構成される．
\par
一次の最適性条件
\begin{equation}
\delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
= -\mu_i \boldsymbol{1}
+ \boldsymbol{\lambda}_i,
\label{eq:kkt_stationarity}
\end{equation}
\par
実行可能性条件
\begin{subequations}
\label{eq:kkt_feasible}
\begin{align}
\boldsymbol{1}^\top \boldsymbol{w}_i &= 1,
\label{eq:kkt_budget}\\
\boldsymbol{w}_i &\ge \boldsymbol{0},
\label{eq:kkt_w_nonneg}\\
\boldsymbol{\lambda}_i &\ge \boldsymbol{0}.
\label{eq:kkt_lambda_nonneg}
\end{align}
\end{subequations}
\par
相補性条件
\begin{equation}
\boldsymbol{\lambda}_i \odot \boldsymbol{w}_i = \boldsymbol{0}.
\label{eq:kkt_complementarity}
\end{equation}
\par
これらを用いることで，次の単一レベル最適化問題が得られる．
\begin{subequations}
\label{eq:dfl_kkt}
\begin{align}
\min_{\boldsymbol{\theta}, \{\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i\}_{i=1}^{T}}
\quad
& \frac{1}{T}\sum_{i=1}^{T}
\left(
-(1-\delta)\boldsymbol{r}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\right),
\label{eq:dfl_kkt_obj}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_nonneg}\\
& \boldsymbol{\lambda}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_lambda_nonneg}\\
& \delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
= -\mu_i \boldsymbol{1}
+ \boldsymbol{\lambda}_i,
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_stationarity}\\
& \boldsymbol{\lambda}_i \odot \boldsymbol{w}_i = \boldsymbol{0},
\qquad i=1,\dots,T.
\label{eq:dfl_kkt_complementarity}
\end{align}
\end{subequations}
\par
この定式化を DFL-QCQP-KKT と呼ぶ．

\subsection{二つの再定式化の性質}
\par
DFL-QCQP-DUAL \eqref{eq:dfl_dual} と DFL-QCQP-KKT \eqref{eq:dfl_kkt} は，理論的には下位問題の最適性条件を表現しており，同一の解集合を持つ．一方で，数値計算の観点からは両者は異なる特徴を持つ．DFL-QCQP-DUAL は相補性条件を含まない一方で，非線形な不等式制約を含む．DFL-QCQP-KKT は相補性条件という非線形制約を含むが，制約の構造はより直接的である．
\par
これらの違いにより，実際の数値計算では，初期化やソルバーの探索挙動に依存して，解の安定性や収束性に差が生じる可能性がある．これらの点については，第4章の数値実験において詳しく検証する．

\section{計算量および解法に関する注意}
\par
本章で示した DFL-QCQP-DUAL および DFL-QCQP-KKT は，いずれも単一レベルの最適化問題として定式化されているが，その計算量的性質には注意が必要である．
\par
まず，両定式化はいずれも非線形制約を含む\textbf{非凸二次計画問題（non-convex QCQP）}であり，一般にはグローバル最適解を保証する多項式時間アルゴリズムは存在しない．そのため，数値計算においては，局所最適解への収束や初期化への依存といった問題が生じ得る．
\par
次に，DFL-QCQP-DUAL と DFL-QCQP-KKT は理論的には下位問題の最適性条件を表現しており，同一の解集合を持つ．しかしながら，数値計算の観点からは両者は異なる特徴を持つ．DFL-QCQP-DUAL は相補性条件を含まない一方で，非線形な不等式制約を含む．一方，DFL-QCQP-KKT は相補性条件という非線形制約を含むが，制約構造はより直接的である．この違いにより，ソルバーの探索挙動や収束性に差が生じる可能性がある．
\par
さらに，本研究で扱う問題は，上位問題と下位問題が強く結合しているため，初期解の選択が数値計算の安定性に影響を与えることがある．特に，異なる初期化を用いた場合に，異なる局所解に収束する可能性がある点には留意が必要である．
\par
以上を踏まえ，本研究では，特定の解法に依存した結論を導くのではなく，複数の再定式化および初期化条件のもとで数値実験を行い，提案手法の挙動と特性を総合的に評価する立場を取る．

\chapter{数値実験}
\par
本章では，第3章で提案した Decision-Focused Learning（DFL）に基づくポートフォリオ最適化手法について，実データを用いた数値実験によりその特性を検証する．本節では，実験の基本方針，使用データ，共分散推定方法，比較手法，ならびに初期化およびソルバー設定について述べる．

\section{実データ実験の設定}

\subsection{実験の基本方針}
\par
第3章で示した DFL-QCQP-DUAL および DFL-QCQP-KKT は，いずれも非凸な二次計画問題として定式化される．このため，数値計算においては初期解やソルバーの探索挙動に依存して，異なる局所解に収束する可能性がある．
\par
本研究では，特定の解法や初期化に依存した性能主張を行うことを目的とせず，意思決定重視学習としての挙動および特性を，実務を想定した設定のもとで評価することを目的とする．そのため，以下の方針に基づいて実験を設計する．
\begin{itemize}
  \item 実データおよび実務的な制約条件を用いる
  \item 比較手法間で，予測モデル，制約条件，評価指標を統一する
  \item 初期化およびソルバー設定を明示し，比較の公平性と再現性を確保する
\end{itemize}

\subsection{使用データおよび学習・再バランス設定}
\par
実データ実験では，短期タクティカル・アセットアロケーション（Tactical Asset Allocation; TAA）を想定し，週次リターンデータを用いる．分析期間は 2006年1月から2025年12月とし，以下の4資産を投資対象とする．
\begin{itemize}
  \item SPY：米国株式（S\&P 500）
  \item GLD：金
  \item EEM：新興国株式
  \item TLT：米国長期国債
\end{itemize}
\par
各時点における特徴量 $\boldsymbol{x}_t$ として，直近26週のリターン平均を用いる．モデルの学習および更新は，以下のローリング手順により行う．
\begin{itemize}
  \item 直近26週のデータを用いて予測モデルのパラメータを推定
  \item 推定したパラメータを次の4週間にわたって固定して使用
  \item 以降，同様の手順を繰り返す
\end{itemize}
\par
この設定は，短期・中期の実務運用における代表的な再バランス頻度を反映している．

\subsection{共分散行列の推定（OAS $\times$ EWMA）}
\par
本研究では，ポートフォリオ最適化に用いる共分散行列 $\boldsymbol{V}_t$ を，時間減衰を考慮した標本共分散行列に対して Oracle Approximating Shrinkage（OAS）を適用する方法により推定する．
\par
まず，時点 $t$ における EWMA 共分散行列 $\boldsymbol{S}_t$ を次式で定義する．
\begin{equation}
\boldsymbol{S}_t
= (1-\alpha)\sum_{k=0}^{L-1}
\alpha^k
(\boldsymbol{r}_{t-k} - \bar{\boldsymbol{r}}_t)
(\boldsymbol{r}_{t-k} - \bar{\boldsymbol{r}}_t)^\top,
\label{eq:ewma_cov}
\end{equation}
\par
ここで，$L=13$ はローリング窓長，$\alpha=0.97$ は時間減衰率であり，実務における業界慣例に基づき固定する．また，$\bar{\boldsymbol{r}}_t$ は同窓内の平均リターンを表す．
\par
次に，OAS に基づく縮小共分散行列 $\boldsymbol{V}_t$ を次のように定義する．
\begin{equation}
\boldsymbol{V}_t
= (1-\phi_t)\boldsymbol{S}_t
+ \phi_t
\frac{\mathrm{tr}(\boldsymbol{S}_t)}{d}
\boldsymbol{I},
\label{eq:oas_cov}
\end{equation}
\par
ここで $\phi_t\in[0,1]$ は縮小強度であり，OAS により解析的に決定される．具体的には，$d$ 次元，共分散推定に用いる（実効的な）サンプルサイズを $n_{\mathrm{eff}}$ とすると，
\begin{equation}
\phi_t
= \min\left\{
1,\ 
\frac{\left(1-\frac{2}{d}\right)\mathrm{tr}(\boldsymbol{S}_t^2)+\mathrm{tr}(\boldsymbol{S}_t)^2}
{\left(n_{\mathrm{eff}}+1-\frac{2}{d}\right)\left(\mathrm{tr}(\boldsymbol{S}_t^2)-\frac{\mathrm{tr}(\boldsymbol{S}_t)^2}{d}\right)}
\right\}.
\label{eq:oas_phi}
\end{equation}
\par
EWMA のように観測に重みを付ける場合，$n_{\mathrm{eff}}$ は「時間減衰率 $\alpha$ に対応する実効サンプルサイズ」とみなせる．本研究のように有限窓 $L$ を用いるとき，重みを正規化した $\tilde{w}_k := \frac{(1-\alpha)\alpha^k}{1-\alpha^L}$（$k=0,\dots,L-1$）に対して
\begin{equation}
n_{\mathrm{eff}}
:= \frac{1}{\sum_{k=0}^{L-1}\tilde{w}_k^2}
= \frac{(1-\alpha^L)^2}{(1-\alpha)^2}\cdot\frac{1-\alpha^2}{1-\alpha^{2L}}
= \frac{1+\alpha}{1-\alpha}\cdot\frac{(1-\alpha^L)^2}{1-\alpha^{2L}}.
\label{eq:neff_ewma}
\end{equation}
\par
特に $L$ が十分大きい場合には $n_{\mathrm{eff}} \approx \frac{1+\alpha}{1-\alpha}$ となる．OAS は，小標本下において標本共分散行列の推定誤差を抑制しつつ，分散構造の情報を保持する点で知られており，本研究のような短期ローリング設定と高い親和性を持つ．

\subsection{トレードオフ係数 $\delta$ の設定}
\par
本研究では，第3章で導入した修正平均--分散コスト関数
\begin{equation}
c(\boldsymbol{w}, \boldsymbol{r})
= -(1-\delta)\boldsymbol{r}^\top \boldsymbol{w}
+ \frac{\delta}{2}\boldsymbol{w}^\top \boldsymbol{V}\boldsymbol{w}
\label{eq:delta_cost}
\end{equation}
を用いる．
\par
実データ実験においては，リスクとリターンのバランスを取った中庸的な設定として $\delta=0.5$ をデフォルト値として固定する．$\delta$ を学習対象や探索変数とせず固定することで，（i）解法の不安定性とパラメータ感度を分離する，（ii）定式化および解法（dual / KKT）の影響に焦点を当てる，という実験設計上の意図を明確にする．

\subsection{比較手法}
\par
実データ実験では，予測モデル，制約条件，評価指標を可能な限り統一したうえで，以下の手法を比較対象として用いる．
\par
\textbf{二段階法（PTO）の基準：}
\begin{itemize}
  \item OLS + MVO（PTO）：期待リターンを最小二乗誤差で推定し，得られた予測値 $\hat{\boldsymbol{r}}$ を平均--分散最適化に入力して配分を決定する，実務でも最も標準的な二段階法．
\end{itemize}
\par
\textbf{予測統合型（IPO）／end-to-end 系：}
\begin{itemize}
  \item IPO（analytic）：ポートフォリオ最適化を予測パラメータ学習に統合した IPO を，制約を外した設定で解析的に解ける形として実装したもの（本研究では初期化・アンカーとしても利用する）．
  \item IPO-GRAD：下位最適化問題を通じて勾配を伝播させる勾配ベースの統合学習（end-to-end）手法．
\end{itemize}
\par
\textbf{Decision-Focused Learning 系：}
\begin{itemize}
  \item SPO+：意思決定誤差の近似勾配を用いる代表的な DFL 手法（ベースライン）．
  \item DFL-QCQP-DUAL / DFL-QCQP-KKT：第3章で導出した dual / KKT 再定式化に基づく提案手法．
\end{itemize}
\par
\textbf{ベンチマーク（運用戦略）：}
\begin{itemize}
  \item Buy-and-Hold（SPY）：株式市場に対する単純な長期保有戦略．
  \item 等分散投資（$1/N$）：推定誤差に依存しない頑健な基準配分．
  \item 時系列モメンタム（TSMOM-SPY）：TAA 的な比較として代表的なトレンドフォロー戦略．
\end{itemize}

\subsection{初期化およびソルバー設定}
\par
第3章で述べたとおり，本研究で扱う最適化問題は非凸であり，初期化およびソルバー設定が数値結果に影響を与える可能性がある．本研究では，非線形最適化ソルバーとして KNITRO を用い，以下の方針で設定を行う．
\begin{itemize}
  \item 内点法（Interior/Direct）を採用する
  \item BFGS による近似ヘッセ行列を使用する
  \item 反復回数および収束許容誤差を十分厳しく設定する
  \item スレッド数を 1 に固定し，再現性を確保する
\end{itemize}
\par
また，DFL 系手法では，現時点の実データ実験では初期値として $\boldsymbol{\theta}=\boldsymbol{0}$ を用い（必要に応じて投資配分は等配分，補助変数は $0$ から開始する），初期化に起因する差をできるだけ抑える．一方で，後続の実験では IPO の解析解（IPO-analytic）に基づく初期化やアンカーも併せて検討し，初期化の影響も含めて評価する．

\section{実験結果}
\par
（後続節）

\section{考察}
\par
（後続節）

\section{補足分析}
\par
（後続節）

\chapter{結論}
\par
本研究では，制約付き平均--分散ポートフォリオ最適化を下位問題として含む Decision-Focused Learning（DFL）を対象に，意思決定誤差に基づく学習問題を二段階最適化問題として定式化した．さらに，下位問題の最適性条件に基づき，強双対性条件に基づく再定式化（DFL-QCQP-DUAL）および KKT 条件に基づく再定式化（DFL-QCQP-KKT）を導出し，単一レベルの非凸二次計画問題（QCQP）として整理した．
\par
また，実務を想定した週次リターンの実データ設定のもとで，データ分割，共分散推定，比較手法，初期化およびソルバー設定を明示し，提案手法の挙動を評価するための実験設計を示した．今後は，第4章で得られる実験結果を踏まえ，定式化の違いが収束性・解の安定性・投資成績に与える影響を整理するとともに，より多資産・より現実的な制約を含む設定への拡張を検討する．

\chapter*{参考文献}
\addcontentsline{toc}{chapter}{\numberline{}参考文献}
\begin{thebibliography}{99}

\bibitem{lee2024returnprediction}
Lee, J.,
\newblock Return Prediction for Mean-Variance Portfolio Selection: How Decision-Focused Learning Shapes Forecasting Models,
\newblock Proceedings of \ldots\ (to appear), 2024.
\par
意思決定重視学習（Decision-Focused Learning; DFL）を平均--分散ポートフォリオ選択に適用し，予測モデルが意思決定構造にどのような影響を与えるかを分析した研究．
\par\bigskip

\bibitem{kim2025covariance}
Kim, J., Tae, I., Lee, Y.,
\newblock Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach,
\newblock arXiv preprint arXiv:2508.10776, 2025.
\par
DFL の枠組みを用いてグローバル最小分散ポートフォリオ（GMVP）の共分散推定問題を再定式化し，意思決定損失最小化の観点から理論的および実証的検討を行った研究．
\par\bigskip

\par\bigskip
\noindent\textbf{一般的な Decision-Focused Learning 理論}
\par\medskip

\bibitem{butlerkwon2021ipo}
Butler, J.\ B., Kwon, S.\ J.,
\newblock Integrating Prediction in Mean-Variance Portfolio Optimization,
\newblock 2021.
\par
予測モデルとポートフォリオ最適化問題を統合的に扱う予測統合型最適化（Integrated Prediction and Optimization; IPO）の枠組みを提案した先行研究．
\par\bigskip

\bibitem{mwp2024dflsurvey}
M.\ W.\ P.\ et al.,
\newblock Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities,
\newblock arXiv preprint, 2024.
\par
Decision-Focused Learning の基礎理論から最新動向，代表的ベンチマークおよび今後の研究課題までを包括的に整理した総説論文．
\par\bigskip

\bibitem{butlerkwon_pessimistic}
Butler, J.\ B., Kwon, S.\ J.,
\newblock Decision-Focused Predictions via Pessimistic Bilevel Optimization: Complexity and Algorithms,
\newblock Journal / arXiv, Year.
\par
DFL を悲観的二段階最適化（pessimistic bilevel optimization）として定式化し，計算複雑性および再定式化手法を理論的に解析した研究．
\par\bigskip

\bibitem{shah2022locallyoptimized}
Shah, S., et al.,
\newblock Learning Locally Optimized Decision Losses,
\newblock Advances in Neural Information Processing Systems (NeurIPS), 2022.
\par
最適化問題を含む意思決定損失の微分可能近似を提案し，DFL の一般的学習枠組みを拡張した研究．
\par\bigskip

\par\bigskip
\noindent\textbf{共分散推定・Shrinkage モデル}
\par\medskip

\bibitem{ledoitwolf2004}
Ledoit, O., Wolf, M.,
\newblock A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices,
\newblock Journal of Multivariate Analysis, 2004.
\par
高次元環境における共分散行列の shrinkage 推定法を提案した基礎的研究．
\par\bigskip

\bibitem{bodnar2021dynamic}
Bodnar, T.,
\newblock Dynamic Shrinkage Estimation of the High-Dimensional Minimum-Variance Portfolio,
\newblock arXiv preprint arXiv:2106.02131, 2021.
\par
GMV ポートフォリオに対する動的 shrinkage 共分散推定モデルを提案した研究．
\par\bigskip

\bibitem{bodnar2022two}
Bodnar, T., Parolya, N., Thors\'en, E.,
\newblock Two Is Better Than One: Regularized Shrinkage of Large Minimum Variance Portfolio,
\newblock arXiv preprint arXiv:2202.06666, 2022.
\par
共分散推定とポートフォリオ重み正則化を同時に行う二重 shrinkage モデルを理論的に分析した研究．
\par\bigskip

\bibitem{tan2020cv}
Tan, V., Zohren, S.,
\newblock Estimation of Large Financial Covariances: A Cross-Validation Approach,
\newblock arXiv preprint arXiv:2012.05757, 2020.
\par
交差検証を用いた大規模金融共分散推定手法を提案した研究．
\par\bigskip

\par\bigskip
\noindent\textbf{伝統的ポートフォリオ最適化理論}
\par\medskip

\bibitem{markowitz1952}
Markowitz, H.,
\newblock Portfolio Selection,
\newblock The Journal of Finance, 1952.
\par
平均--分散ポートフォリオ理論を提唱した近代ポートフォリオ理論の原典．
\par\bigskip

\bibitem{wikipedia_mpt}
Wikipedia contributors,
\newblock Modern Portfolio Theory,
\newblock \url{https://en.wikipedia.org/wiki/Modern_portfolio_theory}.
\par
近代ポートフォリオ理論の概要および基本概念をまとめた補足資料．
\par\bigskip

\par\bigskip
\noindent\textbf{関連応用研究}
\par\medskip

\bibitem{anis2025cardinality}
Anis, H.\ T., et al.,
\newblock End-to-End, Decision-Based, Cardinality-Constrained Portfolio Optimization,
\newblock Journal of \ldots, 2025.
\par
End-to-end 学習と DFL を組み合わせ，組合せ制約付きポートフォリオ最適化問題を扱った研究．
\par\bigskip

\bibitem{kim2025semidfl}
Kim, Juhyeong,
\newblock Semi-Decision-Focused Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization,
\newblock Proceedings of the International Conference on Learning Representations (ICLR), 2025.
\par
Deep Ensemble と DFL を統合した実務志向のロバストポートフォリオ最適化手法を提案した研究．

\end{thebibliography}

\newpage
\chapter*{謝辞}
\addcontentsline{toc}{chapter}{\numberline{}謝辞}
本研究をご指導くださった高野祐一准教授をはじめ，議論に協力してくださった研究室の皆様に深く感謝いたします．
\end{document}
