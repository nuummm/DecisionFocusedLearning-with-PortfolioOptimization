% !TeX root = main.tex
% jreport は 10.5pt を受け付けないため（Unused global option 警告回避）
\documentclass[a4paper,10pt]{jreport}

%========================
% 先輩テンプレ準拠（platex + dvipdfmx）
%========================
\usepackage{test}
\usepackage{silence}
\WarningFilter{caption}{Unknown document class}
\ActivateWarningFilters

% 余白（geometry は使用しない）
% A4 / 上下左右 25mm 相当（TARGET の geometry 設定と同値）
\setlength{\topmargin}{-0.4mm}
\setlength{\oddsidemargin}{-0.4mm}
\setlength{\evensidemargin}{-0.4mm}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{247mm}
\setlength{\headheight}{0mm}
\setlength{\headsep}{0mm}
\setlength{\footskip}{0mm}

\usepackage[dvipdfmx]{graphicx}
\usepackage[dvipdfmx,table]{xcolor}
\usepackage{amsmath}
\numberwithin{equation}{chapter}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[subrefformat=parens]{subcaption}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{float}
\usepackage{comment}
\usepackage{url}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\theoremstyle{definition}
\newtheorem{theorem}{定理}[chapter]
\newtheorem{lemma}{補題}[chapter]
\newtheorem{proposition}{命題}[chapter]
\renewcommand{\proofname}{\normalfont 証明}

% 参考文献見出し（jreport 既定の「関連図書」を「参考文献」に統一）
\renewcommand{\bibname}{参考文献}

% ラベル互換（既存本文が eq:dual_stationarity を参照している場合の救済）
\makeatletter
\AtBeginDocument{%
  \@ifundefined{r@eq:dual_stationarity}{%
    \@ifundefined{r@eq:kkt_stationarity}{}{%
      \global\@namedef{r@eq:dual_stationarity}{\@nameuse{r@eq:kkt_stationarity}}%
    }%
  }{}%
  \@ifundefined{r@prop:local_sensitivity}{%
    \@ifundefined{r@lem:local_sensitivity}{}{%
      \global\@namedef{r@prop:local_sensitivity}{\@nameuse{r@lem:local_sensitivity}}%
    }%
  }{}%
  \@ifundefined{r@eq:lower_qp_sensitivity}{%
    \@ifundefined{r@eq:lower_level_recall}{}{%
      \global\@namedef{r@eq:lower_qp_sensitivity}{\@nameuse{r@eq:lower_level_recall}}%
    }%
  }{}%
}
\makeatother

% 目次深さ
\setcounter{tocdepth}{3}
\newcounter{savedtocdepth}

%========================
% タイトル情報
%========================
\title{意思決定重視学習を用いたポートフォリオ最適化}
\author{野坂 健成}
\academicyear{令和7年度}
\facultyname{筑波大学理工学群社会工学類}
\thesistype{卒業研究論文}
\studentid{学籍番号：202211661}
\advisor{指導教員：高野 祐一 准教授}
\majorfield{経営工学主専攻}
\programfield{}
\yearandmonth{令和7年1月21日提出}
\date{}

\begin{document}

%========================
% 表紙
%========================
\maketitle

%========================
% 目次・図目次（前付）
%========================
\pagenumbering{roman}
\setcounter{tocdepth}{3}
\tableofcontents
\listoffigures
\listoftables
\pagebreak
\setcounter{page}{1}
\pagenumbering{arabic}

%========================
% 第1章：序論
%========================
\chapter{序論}
%========================
% 研究背景
%========================
\section{研究背景}
\par
金融市場における資産運用では，複数資産への資金配分を決定するポートフォリオ最適化が中心的役割を担っている．
ポートフォリオ最適化では一般に，期待リターンとリスクのトレードオフを考慮し，投資家の目的に応じた資産配分を決定することが求められる．
近年では，機械学習手法の発展に伴い，各資産の将来リターンをデータ駆動的に推定し，その推定値をポートフォリオ最適化問題に入力する枠組みが広く用いられている．
このとき多くの場合，推定モデルは平均二乗誤差などの予測誤差を最小化する目的で学習される．
このような学習方針は，予測精度の観点では合理的である一方で，必ずしも最終的な投資成績の改善に直結しないことが指摘されている [7, 9]．
この乖離の一因として，予測と最適化を独立に扱う二段階構造が挙げられる．
すなわち，予測誤差が小さい場合であっても，その誤差が後続の最適化段階において増幅され，投資配分が大きく変動する可能性がある．
この結果，リスク調整後リターンや下方リスク指標などにより評価される投資成績が悪化する場合があり得る．
このような現象は，推定不確実性が大きい局面や，非負制約などの現実的な制約を含む設定において，特に顕在化しやすいことが知られている [4]．
以上の背景から，近年では予測精度そのものではなく，後続の最適化問題を通じて得られる投資成績や意思決定の質を学習目標として
直接最適化する枠組みである意思決定重視学習（Decision-Focused Learning; DFL）が注目されている [9]．DFL は，予測値と実現値の誤差を最小化する
従来の予測精度重視学習（Prediction-Focused Learning; PFL）とは異なり，推定に基づく意思決定が最終的な投資成績にどのような影響を与えるかを明示的に考慮した学習を行う点に特徴がある．

%========================
% 問題設定
%========================
\section{問題設定}

本節では，本研究で扱う意思決定重視学習の問題設定を定式化する．

時点 $i=1,\dots,T$ において，各資産に関する特徴量ベクトルを
$\boldsymbol{x}_i$，当該期間に実現したリターンを
$\boldsymbol{r}_i$ とする．
予測モデルはパラメータ $\boldsymbol{\theta}$ を持ち，
$\boldsymbol{x}_i$ に基づいて各資産の期待リターンの推定値
$\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)$
を出力するものとする．

各時点における投資配分
$\hat{\boldsymbol{w}}_i(\boldsymbol{\theta})$
は，推定値 $\hat{\boldsymbol{r}}_i$ を入力として解かれる
制約付きポートフォリオ最適化問題の最適解として定まる．
ここで $\mathcal{S}$ はポートフォリオ制約によって定まる実行可能集合，
$c(\cdot,\cdot)$ は目的関数を表す（具体的な形は第2章で与える）．
すなわち，次のように定義する.
\[
\hat{\boldsymbol{w}}_i(\boldsymbol{\theta})
\in \arg\min_{\boldsymbol{w}\in\mathcal{S}}
c(\boldsymbol{w},\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i))
\]

一方，比較の基準として，もし時点 $i$ において実現リターン
$\boldsymbol{r}_i$ が事前に既知であったと仮定した場合に得られる
投資配分を，理想的な投資配分として次のように定義する.
\[
\boldsymbol{w}_i^\star
\in \arg\min_{\boldsymbol{w}\in\mathcal{S}}
c(\boldsymbol{w},\boldsymbol{r}_i).
\]
この配分は実運用では利用できないが，
推定に基づく意思決定の妥当性を評価するための基準として用いる．

DFL では，
予測誤差そのものではなく，
推定値に基づいて得られる投資配分が，
理想的な投資配分と比べてどの程度劣っているかという観点から
学習目標を定める．
本研究では，各時点 $i$ におけるこの差を
意思決定誤差として
\[
\ell_i(\boldsymbol{\theta})
=
c(\hat{\boldsymbol{w}}_i(\boldsymbol{\theta}),\boldsymbol{r}_i)
-
c(\boldsymbol{w}_i^\star,\boldsymbol{r}_i)
\]
と定義する．

本研究の学習目標は，
これらの意思決定誤差の時系列平均
\[
\frac{1}{T}\sum_{i=1}^T \ell_i(\boldsymbol{\theta})
\]
を最小化することである．
以上より，本研究で扱う問題は，
制約付きポートフォリオ最適化を下位問題に含み，
その最適解を通じて予測モデルのパラメータを学習する
二段階最適化問題として定式化される．

%========================
% 関連研究
%========================
\section{関連研究}

ポートフォリオ最適化は Markowitz による平均--分散ポートフォリオ最適化
（Mean--Variance Optimization; MVO）\cite{markowitz1952}
を起点として発展してきた．
MVO は期待リターンとリスクを明示的に扱えるため，
理論的にも実務的にも解釈しやすい基準モデルとして広く用いられている．
一方で，MVO の入力となる期待リターンの推定は，
回帰・時系列モデルから機械学習まで幅広く研究されており，
推定誤差が最適配分に与える影響が大きいことが知られている．
特に Chopra and Ziemba\cite{chopraziemba1993} は，
平均推定誤差がポートフォリオの効用や配分に与える影響を
定量的に示している．

従来の多くの研究および実務では，
予測モデルを平均二乗誤差などの予測誤差を最小化する目的で学習し，
得られた推定値を最適化問題に入力して投資配分を決定する
二段階構造が採用されてきた\cite{lahoud2025}．
しかしこの枠組みでは，
予測モデルの学習目標と，
後続の最適化で最終的に評価される投資目的が
必ずしも一致しないため，
予測精度の向上が投資成績の改善に直結しない場合があり得る\cite{mandi2024}．

この課題に対し，
予測と最適化を統合的に扱い，
意思決定の質に基づいて学習を行う枠組みとして
DFL が提案されている\cite{mandi2024}．
DFL では，
学習過程に最適化問題を組み込み，
最適化解を介して定義される意思決定基準を
直接最小化することにより，
上述のギャップを緩和することを目指す．
さらに，
平均--分散ポートフォリオ選択に DFL を適用し，
意思決定構造が推定モデルの学習に与える影響を
分析する研究も報告されている\cite{lee2025}．

また，
MVO を対象として
推定と最適化を統合的に扱う具体的手法として
Integrating Prediction in Mean–Variance
Portfolio Optimization (IPO) が提案されている\cite{butlerkwon2023}．
IPO は，推定モデルの学習段階に最適化問題を直接組み込むことで，
意思決定に即したパラメータ更新を可能にする一方で，
非凸最適化に起因する数値的安定性や初期値依存性が課題として指摘されている．
加えて，
DFL を悲観的二段階最適化として捉える理論的整理\cite{bucarey2024} や，
数値安定性・アルゴリズムの観点からの検討\cite{shah2022}
も進められている．

これらの既存研究では，
DFL に基づく学習枠組みや理論的性質は広く議論されている一方で，
制約付き平均--分散ポートフォリオ最適化を下位問題に持つ設定において，
異なる再定式化が数値計算上どのような挙動の差を示すかについては，
体系的な整理が十分になされていない．

%========================
% 本研究の貢献
%========================
\section{本研究の貢献}

本研究は，制約付き平均--分散ポートフォリオ最適化を下位問題に含む DFL を対象として，
定式化と実証の両面から検討を行う．
本研究の主な貢献は以下のとおりである．

\begin{enumerate}
  \item 下位問題の最適性条件に基づき，
  単一レベル最適化として表現される2通りの同値再定式化を導出し，
  両者の理論的関係を整理した．
  これにより，制約付きMVOを含むDFLを実装・検討するための共通の基盤を与えた．

  \item 数値計算上の実装容易性と安定性の観点から，
  DFL-OPT-K を主たる提案手法として採用し，
  週次TAAを想定した実データ実験を通じて，
  従来の PFL と比較した投資成績に基づく意思決定品質の改善可能性を検証した．

  \item 提案手法から得られた解に基づく分析を通じて，挙動の解釈可能性を整理した．
\end{enumerate}

%========================
% 論文構成
%========================
\section{論文構成}

本論文の構成は以下のとおりである．
第2章では，既存手法として PFL および予測統合型手法を整理する．
第3章では，提案手法を二段階最適化として再定式化し，両者の関係を示す．
第4章では，提案手法を用いた実データ実験により，
性能および挙動の特性を検証する．
第5章では，結論を述べる．

%==================================================================================================
% 第2章：既存手法
%==================================================================================================
\chapter{既存手法}
本章では，本研究の位置づけを明確にするため，
ポートフォリオ最適化における代表的な既存手法を整理する．
まず，基準モデルとして平均--分散ポートフォリオ最適化を概説し，
次に，推定と最適化の関係性に着目した代表的な学習枠組みとして，
予測精度重視学習（PFL），予測統合型アプローチ（IPO），
および意思決定考慮型アプローチ（SPO+）を紹介する．
さらに，近年提案された悲観的二段階最適化に基づく
意思決定重視学習の理論的枠組みについて述べ，
本研究との関係を明確にする．
%========================
% ポートフォリオ最適化モデル
%========================
\section{ポートフォリオ最適化モデル}

本研究では，Markowitz による平均--分散ポートフォリオ最適化
（Mean--Variance Optimization; MVO）\cite{markowitz1952}
を基準モデルとして採用する．
MVO は，期待リターンとリスクのトレードオフを
明示的に定式化できる点で，
理論的にも実務的にも広く用いられている．

資産数を $d$，
投資配分ベクトルを $\boldsymbol{w}\in\mathbb{R}^d$，
期待リターンベクトルを $\boldsymbol{r}\in\mathbb{R}^d$ とする．
本研究では，共分散行列 $\boldsymbol{V}$ は
正定値対称行列であると仮定し，
$\boldsymbol{V}\in\mathbb{S}_{++}^d$ とする．
平均--分散モデルに基づくポートフォリオ最適化問題は，
次の目的関数を，
予算制約および非負制約の下で最小化する問題として
定式化される：
\begin{align}
c(\boldsymbol{w}, \boldsymbol{r})
&:= -(1-\delta)\boldsymbol{r}^\top \boldsymbol{w}
+ \frac{\delta}{2}\boldsymbol{w}^\top \boldsymbol{V}\boldsymbol{w},
\\
\boldsymbol{1}^\top \boldsymbol{w}
&= 1,
\\
\boldsymbol{w}
&\ge \boldsymbol{0}.
\end{align}
ここで $0<\delta\le1$ は，
期待リターン項と分散リスク項の相対的な重みを制御する
パラメータである．
$\boldsymbol{V}\in\mathbb{S}_{++}^d$ であるため，
目的関数は強凸であり，
実行可能集合が非空である限り，
本問題は大域的最適解を一意に持つ凸二次計画問題となる．

実際の運用では，
期待リターン $\boldsymbol{r}$ および共分散行列 $\boldsymbol{V}$ は未知であり，
過去データから推定される．
特に期待リターンの推定誤差は，
最適化問題の解に大きな影響を与えることが知られている\cite{chopraziemba1993}．
このため，
回帰モデルや時系列モデル，
近年では機械学習手法を用いて期待リターンを推定し，
その推定値を最適化問題に入力するという枠組みが
実務・研究の双方で一般的に用いられている\cite{lahoud2025}．

本研究では，
期待リターンが特徴量に対して線形に表現できると仮定し，
次の予測モデルを用いる．
\begin{equation}
\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)
=
\mathrm{diag}(\boldsymbol{x}_i)\boldsymbol{\theta},
\label{eq:prediction_model}
\end{equation}
ここで $\boldsymbol{x}_i\in\mathbb{R}^d$ は特徴量ベクトル，
$\boldsymbol{\theta}\in\mathbb{R}^d$ は回帰係数である．
$\boldsymbol{\theta}$ は，
予測誤差の最小化に基づく最小二乗問題
\begin{equation}
\min_{\boldsymbol{\theta}}
\frac{1}{T}\sum_{i=1}^T
\left\|
\boldsymbol{r}_i-
\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)
\right\|_2^2
\end{equation}
を解くことで推定される．
このように，
予測誤差の最小化により推定モデルを学習し，
得られた推定値を用いてポートフォリオ最適化を行う
二段階構造を，
本稿では予測精度重視学習（PFL）と呼ぶ\cite{mandi2024}．

%========================
% 予測統合型アプローチ
%========================
\section{予測統合型アプローチ}

推定と最適化を分離して扱う従来の二段階構造に対し，
Butler and Kwon \cite{butlerkwon2023} は，
平均--分散ポートフォリオ最適化を対象として，
推定モデルの学習過程に最適化問題を直接組み込む
予測統合型アプローチを提案した．
この手法は
Integrating Prediction in Mean--Variance Portfolio Optimization（IPO）
と呼ばれる．

IPO の基本的な考え方は，
予測誤差の最小化ではなく，
推定値に基づいて得られる最終的な投資配分の良さを通じて，
予測モデルのパラメータを更新する点にある．
すなわち，
予測モデルのパラメータを上位変数，
制約付き平均--分散ポートフォリオ最適化を下位問題とする
二段階最適化問題として学習を定式化することで，
予測と最適化を明示的に結合する．

一方で，
IPO における上位問題は一般に非凸となり，
勾配ベースの手法により学習が行われる．
そのため，
計算コストの増大や
初期値に依存した局所解への収束といった課題が生じ得る．
また，
非負制約や予算制約を含む
実務的な平均--分散ポートフォリオ最適化においては，
数値的安定性の確保が必ずしも容易でない場合がある．

%========================
% 意思決定考慮型アプローチ
%========================
\section{意思決定考慮型アプローチ}

推定と最適化を分離して扱う従来の二段階構造に対し，
Elmachtoub and Grigas \cite{elmachtoubgrigas2022} は，
最適化問題の構造を学習に反映させる手法として
Smart Predict--then--Optimize（SPO+）を提案した．
SPO+ は，
二段階法の枠組みを維持しつつ，
最適化問題に由来する surrogate loss を用いて
予測モデルを学習する点に特徴がある．
この意味で，
SPO+ は純粋な予測精度重視学習よりも
意思決定を考慮した学習を行う一方，
最適化問題を学習ループに直接組み込む
意思決定重視学習とは異なり，
二段階構造に基づくアプローチと位置づけられる．

本研究では，
SPO+ を二段階法における意思決定考慮型手法の代表例として位置づけ，
比較対象に含める．

%========================
% 悲観的二段階最適化に基づく DFL
%========================
\section{悲観的二段階最適化に基づく DFL}

Bucarey ら\cite{bucarey2024}は，
意思決定重視学習における期待後悔最小化問題を，
悲観的二段階最適化として厳密に定式化した．
この枠組みでは，
予測値に基づいて解かれる下位最適化問題が
複数の最適解を持つ場合に，
その中から上位目的を最も悪化させる解が選択されるという
悲観的解概念に基づいて後悔が定義される．

同論文は，
この期待後悔最小化問題が計算的に困難であることを理論的に示し，
制限された設定においても
NP 完全であることを明らかにしている．
さらに，
双対性に基づく議論により，
当該の悲観的二段階最適化問題を
単一レベルの非凸な二次最適化問題として
再定式化できることを示し，
具体的な意思決定問題に対する計算手法および数値実験を報告している．

本研究は，
この理論的枠組みを踏まえつつ，
制約付き平均--分散ポートフォリオ最適化という
具体的な意思決定問題を対象として，
最適性条件に基づく再定式化を比較可能な形で整理し，
後続章における解法設計および実証分析へと接続する．

%=================================================================================
% 第3章：提案手法
%=================================================================================
\chapter{提案手法}

%========================
% 二段階最適化モデル
%========================
\section{二段階最適化モデル}

本節では，
制約付き平均--分散ポートフォリオ最適化を下位問題に含む
意思決定重視学習（DFL）の問題設定を明示し，
後続の再定式化に向けて，
二段階最適化問題としての構造を厳密に定式化する．

時点 $i=1,\dots,T$ において，
特徴量ベクトル $\boldsymbol{x}_i\in\mathbb{R}^d$ および
実現リターン $\boldsymbol{r}_i\in\mathbb{R}^d$ が観測されるとする．
期待リターンの推定値は，
第2章で導入した線形モデル
\eqref{eq:prediction_model} により与えられるものとし，
$\boldsymbol{\theta}\in\mathbb{R}^d$ を学習対象のパラメータとする．

%========================
% 下位問題：制約付きポートフォリオ最適化
%========================
\subsection*{下位問題：制約付きポートフォリオ最適化}

推定値 $\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)$ を入力として，
各時点 $i$ における投資配分
$\hat{\boldsymbol{w}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)$ を，
次の制約付き最適化問題の解として定義する．
\begin{equation}
\hat{\boldsymbol{w}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)
\in
\arg\min_{\boldsymbol{w}_i\in\mathcal{S}}
c\!\left(
\boldsymbol{w}_i,
\hat{\boldsymbol{r}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)
\right),
\label{eq:lower_level_new}
\end{equation}
ここで目的関数 $c(\cdot,\cdot)$ は
\begin{equation}
c(\boldsymbol{w}_i,\boldsymbol{r})
=
-(1-\delta)\boldsymbol{r}^\top\boldsymbol{w}_i
+
\frac{\delta}{2}\boldsymbol{w}_i^\top\boldsymbol{V}_i\boldsymbol{w}_i,
\quad 0<\delta\le1,
\end{equation}
制約集合 $\mathcal{S}$ は
\begin{equation}
\mathcal{S}
=
\left\{
\boldsymbol{w}_i\in\mathbb{R}^d
\ \middle|\
\boldsymbol{1}^\top\boldsymbol{w}_i=1,\;
\boldsymbol{w}_i\ge\boldsymbol{0}
\right\}
\end{equation}
で与えられる．
共分散行列 $\boldsymbol{V}_i$ は
$\boldsymbol{V}_i\in\mathbb{S}_{++}^d$ と仮定する．

また，各時点 $i$ において実現リターン $\boldsymbol{r}_i$ が既知であると仮定した場合の
理想的な投資配分を
\begin{equation}
\boldsymbol{w}_i^*
\in
\arg\min_{\boldsymbol{w}_i \in \mathcal{S}}
c(\boldsymbol{w}_i, \boldsymbol{r}_i)
\end{equation}
として定義する．
この配分は実運用では利用できないが，
後述する学習目的を定義するための基準として用いられる．

%========================
% 上位問題：意思決定誤差最小化
%========================
\subsection*{上位問題：意思決定誤差最小化}

各時点 $i$ における意思決定誤差を
\begin{equation}
\ell_i(\boldsymbol{\theta})
=
c\!\left(
\hat{\boldsymbol{w}}_i(\boldsymbol{\theta},\boldsymbol{x}_i),
\boldsymbol{r}_i
\right)
-
c(\boldsymbol{w}_i^*,\boldsymbol{r}_i)
\end{equation}
と定義すると，
本研究で扱う学習問題は，
次の二段階最適化問題として表される．
\begin{align}
\min_{\boldsymbol{\theta}}\quad
&\frac{1}{T}\sum_{i=1}^T \ell_i(\boldsymbol{\theta}),
\label{eq:upper_level_obj}
\\
\text{s.t.}\quad
&
\hat{\boldsymbol{w}}_i(\boldsymbol{\theta},\boldsymbol{x}_i)
\ \text{は}\ \eqref{eq:lower_level_new}\ \text{の最適解}.
\label{eq:upper_level_constraint}
\end{align}

上記の定式化は，
下位問題に $\arg\min$ 演算子を含むため，
そのままでは数値計算上の取り扱いが困難である．
次節では，
下位問題の最適性条件を用いることにより，
この二段階構造を
単一レベルの最適化問題へと再定式化する．

%========================
% 再定式化
%========================
\section{再定式化}

本節では，前節で定義した二段階最適化問題を，
下位問題の最適性条件に基づいて単一レベル化する．
具体的には，
(1) KKT 条件を明示的に組み込む定式化と，
(2) 強双対性に基づく最適値一致条件を用いる定式化
の2通りを示す．

%========================
% 下位問題のラグランジュ関数
%========================
\subsection*{下位問題のラグランジュ関数}

各時点 $i$ における下位問題 \eqref{eq:lower_level_new} を再掲する．
簡単のため $\hat{\boldsymbol{r}}_i := \hat{\boldsymbol{r}}_i(\boldsymbol{\theta}, \boldsymbol{x}_i)$ とおく．
\begin{align}
\min_{\boldsymbol{w}_i} \quad
& -(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i,
\label{eq:lower_level_recall}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\label{eq:lower_level_recall_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0}.
\label{eq:lower_level_recall_nonneg}
\end{align}
等式制約および不等式制約に対応するラグランジュ乗数を
それぞれ $\mu_i\in\mathbb{R}$，$\boldsymbol{\lambda}_i\in\mathbb{R}^d_{\ge 0}$ とすると，
ラグランジュ関数は次のように与えられる．
\begin{equation}
\mathcal{L}_i(\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i)
=
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
+ \mu_i\,(1-\boldsymbol{1}^\top \boldsymbol{w}_i)
- \boldsymbol{\lambda}_i^\top \boldsymbol{w}_i
\label{eq:lagrangian}
\end{equation}

%========================
% KKT 条件に基づく再定式化（主）
%========================
\subsection*{KKT 条件に基づく再定式化}

まず，下位問題 \eqref{eq:lower_level_recall} は，
$\delta>0$ および $\boldsymbol{V}_i\succ\boldsymbol{0}$ のもとで
目的関数が強凸な凸二次計画問題である．
また，等式制約および不等式制約からなる実行可能集合は非空であり，
Slater 条件が成立する．
したがって，本問題に対して KKT 条件は最適性の必要十分条件となり，以下の4つから構成される．
\begin{itemize}
\item 一次の最適性条件
\begin{equation}
\delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
- \mu_i \boldsymbol{1}
- \boldsymbol{\lambda}_i
= \boldsymbol{0},
\label{eq:kkt_stationarity}
\end{equation}

\item 実行可能性
\begin{align}
\boldsymbol{1}^\top \boldsymbol{w}_i &= 1,
\label{eq:kkt_budget}\\
\boldsymbol{w}_i &\ge \boldsymbol{0},
\label{eq:kkt_w_nonneg}
\end{align}

\item 双対実行可能性
\begin{equation}
\boldsymbol{\lambda}_i \ge \boldsymbol{0},
\label{eq:kkt_lambda_nonneg}
\end{equation}

\item 相補性条件
\begin{equation}
\boldsymbol{\lambda}_i \odot \boldsymbol{w}_i = \boldsymbol{0}.
\label{eq:kkt_complementarity}
\end{equation}
\end{itemize}

以上の KKT 条件を下位問題の最適性条件として
上位問題に組み込むことにより，
次の単一レベル最適化問題が得られる．
\begin{align}
\min_{\boldsymbol{\theta}, \{\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i\}_{i=1}^{T}}
\quad
& \frac{1}{T}\sum_{i=1}^{T}
 \left(
-(1-\delta)\boldsymbol{r}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\right),
\label{eq:dfl_kkt_obj}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_nonneg}\\
& \boldsymbol{\lambda}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_lambda_nonneg}\\
& \delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
- \mu_i \boldsymbol{1}
- \boldsymbol{\lambda}_i
= \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_kkt_stationarity}\\
& \boldsymbol{\lambda}_i \odot \boldsymbol{w}_i = \boldsymbol{0},
\qquad i=1,\dots,T.
\label{eq:dfl_kkt_complementarity}
\end{align}
この定式化を DFL-OPT-K と呼ぶ．

%========================
% 強双対性条件に基づく再定式化（代替）
%========================
\subsection*{強双対性条件に基づく再定式化}

次に，同じ下位問題に対して，
強双対性に基づく最適値一致条件を用いた別表現を与える．
下位問題 \eqref{eq:lower_level_recall} は前述の通り Slater 条件を満たす凸最適化問題であるため，
強双対性が成立する．

ここで stationarity \eqref{eq:dfl_dual_stationarity} と予算制約 $\boldsymbol{1}^\top\boldsymbol{w}_i=1$ を用いると，
\[
\delta \boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
-\mu_i
=
\boldsymbol{\lambda}_i^\top \boldsymbol{w}_i
\]
が成り立つ．
したがって，最適性における相補性 $\boldsymbol{\lambda}_i^\top\boldsymbol{w}_i=0$ は，
次の「最適値一致」に等価な等式として書ける．（導出の詳細は Appendix に示す．）
\begin{equation}
\delta \boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
=\mu_i.
\label{eq:dual_strong_simplified}
\end{equation}

以上より，二段階最適化問題 \eqref{eq:upper_level_obj}--\eqref{eq:upper_level_constraint} は，
次の単一レベル最適化問題として再定式化できる：
\begin{align}
\min_{\boldsymbol{\theta}, \{\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i\}_{i=1}^{T}}
\quad
& \frac{1}{T}\sum_{i=1}^{T}
 \left(
-(1-\delta)\boldsymbol{r}_i^\top \boldsymbol{w}_i
+ \frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\right),
\label{eq:dfl_dual_obj}\\
\text{s.t.} \quad
& \boldsymbol{1}^\top \boldsymbol{w}_i = 1,
\qquad i=1,\dots,T,
\label{eq:dfl_dual_budget}\\
& \boldsymbol{w}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_dual_nonneg}\\
& \boldsymbol{\lambda}_i \ge \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_dual_lambda_nonneg}\\
& \delta \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i
- \mu_i \boldsymbol{1}
- \boldsymbol{\lambda}_i
= \boldsymbol{0},
\qquad i=1,\dots,T,
\label{eq:dfl_dual_stationarity}\\
& \delta \boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
= \mu_i,
\qquad i=1,\dots,T.
\label{eq:dfl_dual_value}
\end{align}
この定式化を DFL-OPT-D と呼ぶ．

%（補足）\eqref{eq:dfl_dual_value} は \eqref{eq:dfl_dual_stationarity} と
%予算制約を通じて $\boldsymbol{\lambda}_i^\top\boldsymbol{w}_i=0$ を含意し，
%$\boldsymbol{w}_i\ge\boldsymbol{0}$ および $\boldsymbol{\lambda}_i\ge\boldsymbol{0}$ と併せて
%相補性条件に対応する．

%========================
% DFL-OPT-D と DFL-OPT-K の関係
%========================
\begin{lemma}[二つの再定式化の同値性]
\label{prop:equivalence}
各 $i=1,\ldots,T$ に対して，
下位問題 \eqref{eq:lower_level_recall} が凸二次計画問題であり
Slater 条件を満たすと仮定する．
このとき，
DFL-OPT-D と DFL-OPT-K は同一の解集合を持つ．
\end{lemma}

本研究では，以降の解析の簡潔さの観点から，
KKT 条件に基づく定式化 DFL-OPT-K を用いる．

%========================
% 制約付き平均--分散最適化における解の構造と安定
%========================
\begin{lemma}[制約付き平均--分散最適化における解の構造と安定性]
\label{lem:structure_stability}

$\delta>0$ および $\boldsymbol{V}\succ\boldsymbol{0}$ とし，
制約付き平均--分散ポートフォリオ最適化問題
\eqref{eq:lower_level_recall}
を考える．
このとき，下位問題は強凸であり，最適解 $\boldsymbol{w}^*$ は一意に定まる．
さらに，不等式制約のアクティブ集合が近傍で不変である局所においては，
最適解 $\boldsymbol{w}^*$ は，
精度行列 $\boldsymbol{V}^{-1}$ による線形写像
$(1-\delta)\boldsymbol{V}^{-1}\hat{\boldsymbol{r}}$
を基準とし，
等式制約 $\boldsymbol{1}^\top\boldsymbol{w}=1$ および
アクティブ制約によって定まる可行部分空間への
射影として表される．
このとき，推定誤差 $\Delta\hat{\boldsymbol{r}}$ に対する最適解の変動は，
\begin{equation}
\|\Delta \boldsymbol{w}^*\|_2
\;\le\;
C\,
\frac{1-\delta}{\delta}\,
\frac{1}{\lambda_{\min}(\boldsymbol{V})}\,
\|\Delta \hat{\boldsymbol{r}}\|_2
\label{eq:structure_stability_bound}
\end{equation}
を満たす定数 $C<\infty$ により上から抑えられる．
ここで $C$ は制約集合およびアクティブ集合の構造にのみ依存し，
$\boldsymbol{V}$ および $\hat{\boldsymbol{r}}$ には依存しない．

したがって，制約付き平均--分散最適化における最適解の安定性
（すなわち推定誤差の増幅度）は，
リスク重み $\delta$ と
共分散行列 $\boldsymbol{V}$ の最小固有値
$\lambda_{\min}(\boldsymbol{V})$
によって構造的に支配される．
\end{lemma}

補題 \ref{lem:structure_stability} は，最適性条件に基づく定式化を通じて，
制約付き平均--分散最適化における最適解の構造と安定性を
解析的に明示した点に意義がある．
特に，最適解の安定性が共分散行列の最小固有値によって
支配されることが明らかになる．

この観点からは，共分散行列に対する等方的縮小が，
推定誤差の増幅を抑制する方向に作用することを
自然に解釈することができる．
補題の厳密な導出は Appendix に示す．

%==============================================================================
% 第4章：数値実験
%===============================================================================
\chapter{数値実験}
\par
\noindent
本章では,第3章で提案した DFL-OPT-D および DFL-OPT-K の数値的挙動と実務的有効性を,実データを用いたタクティカル・アセット・アロケーション（Tactical Asset Allocation; TAA）の文脈で評価する.特に,（i）dual 定式化と KKT 定式化の数値的差異,（ii）初期化の影響,（iii）提案手法がどのような状況で相対的な優位性を示すか,という点に焦点を当てる.
%========================
% 実データ実験の設定
%========================
\section{実データ実験の設定}
\par
\noindent
本節では,実験の基本方針,使用データ,共分散推定方法,比較手法,ならびに初期化およびソルバー設定について述べる.本章を通じて,比較手法間で実験設定を可能な限り統一し,学習枠組みおよび定式化の違いに起因する差異に焦点を当てる.
%========================
% 実験の基本方針
%========================
\subsection*{実験の基本方針}
\par
第3章で示したとおり, DFL-OPT-D および DFL-OPT-K はいずれも,下位に制約付き平均--分散最適化問題を含む非凸な非線形最適化問題として定式化される.そのため,数値計算においては初期解やソルバー設定に依存して,異なる局所解へ収束する可能性がある.
\par
本研究の目的は,特定の初期化やハイパーパラメータ調整によって得られた「最良の局所解」を主張することではない.むしろ,実務的に自然な制約条件と統一された実験設定の下で, DFL に基づく定式化がどのような挙動・特性を示すかを体系的に評価することを目的とする.
\par
このため,本章では可能な限り
\begin{itemize}
  \item 使用データ
  \item 特徴量設計
  \item 制約条件
  \item 評価指標
  \item 初期化およびソルバー設定
\end{itemize}
を比較手法間で統一し,モデル構造および学習方式の違いそのものに起因する差異に焦点を当てる.
%========================
% 使用データおよび学習・再バランス設定
%========================
\subsection*{使用データおよび学習・再バランス設定}
\par
実データ実験では,短期タクティカル・アセット・アロケーション（Tactical Asset Allocation; TAA）を想定し, Yahoo Finance から取得した調整後終値に基づく週次リターン（2006 年 1 月から 2025 年 12 月）を用いる.投資対象は,異なるリスク特性を代表する ETF として,以下の 4 資産を選択する.
\begin{itemize}
  \item SPDR S\&P 500 ETF Trust（SPY）：米国株式
  \item SPDR Gold Shares（GLD）：金
  \item iShares MSCI Emerging Markets ETF（EEM）：新興国株式
  \item iShares 20+ Year Treasury Bond ETF（TLT）：米国長期国債
\end{itemize}
\par
各時点 $t$ における特徴量 $\boldsymbol{x}_t$ として,直近 26 週の週次リターン平均を用いる.これは,短期的なトレンド情報を反映しつつ,週次データに内在するノイズを一定程度平滑化するための設定である.
\par
モデルの学習およびポートフォリオの更新はローリング手順に基づき,直近 26 週（約半年）の週次リターンを用いて推定を行い,推定したパラメータは次の 4 週間（約 1 か月）にわたって固定して用いる.これにより,週次データの短期ノイズに過度に反応することを抑えつつ,半年程度の情報に基づく短期的な状態推定と月次の運用更新という時間スケールを両立する.
\par
なお,以降の実験ではリスクとリターンのトレードオフ係数を中庸的な設定として $\delta=0.5$ に固定する.本章ではハイパーパラメータ最適化は目的とせず,すべての手法で学習窓長と更新頻度を共通に固定することで,第 3 章の定式化および学習枠組みの差異の影響を比較する.
%========================
% 共分散行列の推定
%========================
\subsection*{共分散行列の推定}
\par
本研究では,ポートフォリオ最適化に用いる共分散行列 $\boldsymbol{V}_t$ を,
時間減衰を考慮した標本共分散行列に対して Oracle Approximating Shrinkage（OAS）を適用する方法により推定する \cite{chen2010oas}.
\par
まず,時点 $t$ における EWMA 共分散行列 $\boldsymbol{S}_t$ を次式で定義する.
\begin{equation}
\boldsymbol{S}_t
= (1-\alpha)\sum_{k=0}^{L-1}
\alpha^k
(\boldsymbol{r}_{t-k} - \bar{\boldsymbol{r}}_t)
(\boldsymbol{r}_{t-k} - \bar{\boldsymbol{r}}_t)^\top,
\label{eq:ewma_cov}
\end{equation}
\par
ここで,$L=13$ はローリング窓長（約四半期）であり,本研究の短期ローリング設定に基づき固定する.また,$\alpha=0.97$ は時間減衰率であり,
実務における業界慣例に基づき固定する \cite{jpm2006riskmetrics}.$\bar{\boldsymbol{r}}_t$ は同窓内の平均リターンを表す.
\par
次に,OAS に基づく縮小共分散行列 $\boldsymbol{V}_t$ を次のように定義する.
\begin{equation}
\boldsymbol{V}_t
= (1-\phi_t)\boldsymbol{S}_t
+ \phi_t
\frac{\mathrm{tr}(\boldsymbol{S}_t)}{d}
\boldsymbol{I},
\label{eq:oas_cov}
\end{equation}
\par
ここで $\phi_t\in[0,1]$ は縮小強度であり,OAS により解析的に決定される.また,EWMA のように観測に重みを付ける場合,$n_{\mathrm{eff}}$ は「時間減衰率 $\alpha$ に対応する実効サンプルサイズ」とみなせる \cite{jpm2006riskmetrics}.OAS は,小標本下において標本共分散行列の推定誤差を抑制しつつ,分散構造の情報を保持する点で知られており,本研究のような短期ローリング設定と高い親和性を持つ \cite{chen2010oas}.縮小係数 $\phi_t$ および $n_{\mathrm{eff}}$ の具体式は Appendix に示す.
\par
本研究では,共分散推定手法の比較や最適化は目的とせず,すべての手法に対して同一の $\boldsymbol{V}_t$ を用いる.これにより,推定リターンと意思決定の統合方法（PFL / IPO / DFL）の違いに焦点を当てる.
%========================
% 評価指標
%========================
\subsection*{評価指標}
\par
本章の数値実験におけるポートフォリオ性能の評価には,リターン水準,リスク水準,リスク調整後パフォーマンス,および売買行動の安定性を多面的に捉えるため,以下の指標を用いる.いずれの指標も,取引コスト（bps）を考慮した実行ベースの損益系列に基づいて算出する.
\par
\noindent リターン指標
\begin{itemize}
  \item 年率リターン（Annualized Return）：期間全体の累積リターンから年率換算した平均成長率を用いる.
  \item 最終資産価値（Final Wealth）：初期資産を 1 としたときの評価期間終了時点における累積資産額を用いる.
\end{itemize}
\par
\noindent リスク調整後指標
\begin{itemize}
  \item Sharpe 比：無リスク利子率を 0 と仮定し,年率リターンを年率ボラティリティで除した値として定義する.
    \[
    \mathrm{Sharpe}=\frac{\mu}{\sigma},
    \]
    ここで $\mu$ は年率リターン,$\sigma$ は年率ボラティリティである.
\end{itemize}
\par
\noindent リスク指標
\begin{itemize}
  \item 年率ボラティリティ（Annualized Volatility）：週次リターンの標準偏差を年率換算した値とする.
  \item 最大ドローダウン（Maximum Drawdown）：累積資産曲線におけるピークからの最大下落率を測定する.
  \item CVaR$_{95}$：リターン分布の下位 5\% における平均損失を用い,極端な損失リスクを評価する.
\end{itemize}
\par
\noindent 売買行動・安定性指標
\begin{itemize}
  \item 平均ターンオーバー（Turnover）：各リバランス時点におけるポートフォリオ変更量の平均値を用いる.
  \item スイッチ頻度（Switch Frequency）：リバランス時点において,最大ウェイトを持つ資産が前期から変更された割合を測定する.本指標は,意思決定の安定性およびポートフォリオ構成の急激な変化の度合いを捉える目的で導入する.
\end{itemize}
\par
以上の評価指標は,すべての比較手法に対して同一の定義および算出方法を適用する.これにより,
手法間の性能差が定式化および学習枠組みの違いに起因するものであることを明確にする.

%========================
% 比較手法
%========================
\subsection*{比較手法}
\par
実データ実験では,予測モデルや制約条件等を可能な限り統一したうえで,以下の手法を比較対象として用いる.
\par
\noindent 提案手法
\begin{itemize}
  \item DFL-OPT-D：第3章で導出した強双対性条件に基づく提案手法.
  \item DFL-OPT-K：第3章で導出した KKT 条件に基づく提案手法.
\end{itemize}
\par
\noindent Prediction-Focused Learning の基準
\begin{itemize}
  \item OLS + MVO：期待リターンを最小二乗誤差で推定し,得られた推定値 $\hat{\boldsymbol{r}}$ を平均--分散最適化に入力して配分を決定する,実務でも標準的な構成.これを PFL の基準手法として採用する.
\end{itemize}
\par
\noindent 予測統合型手法
\begin{itemize}
  \item IPO-GRAD：最適化問題を学習ループに組み込み,下位最適化問題を通じて勾配を伝播させる End-to-End 手法 \cite{butlerkwon2023}.
\end{itemize}
\par
\noindent Decision-Focused Learning 系
\begin{itemize}
  \item DFL-CF：\eqref{eq:upper_level_obj}--\eqref{eq:upper_level_constraint} の下位問題において
  制約を外した場合に得られる解析解に基づく手法であり,\cite{butlerkwon2023} に示される解析的解に対応する.
  本研究では,解析解ベースの基準および初期化候補として用いる.
  \item SPO+：線形最適化問題に対して機会損失の凸上界を構成することで,勾配ベースの学習を可能にした手法 \cite{elmachtoubgrigas2022}.本研究の制約付き平均--分散問題には直接適用できないため,近似的設定により比較対象に含める.
\end{itemize}
\par
\noindent ベンチマーク（運用戦略）
\begin{itemize}
  \item Buy-and-Hold（S\&P 500）：株式市場に対する単純な長期保有戦略.
  \item 等分散投資（$1/N$）：推定誤差に依存しない頑健な基準配分.
\end{itemize}

%========================
% 初期化およびソルバー設定
%========================
\subsection*{初期化およびソルバー設定}
\par
第3章で述べたとおり,本研究で扱う最適化問題は非凸であり,初期化により到達する局所解が変化し得る.
本研究では,非線形最適化ソルバーとして KNITRO を用い,ソルバー設定は原則として全手法で統一する.
\par
DFL 系手法では,実データ実験におけるデフォルト初期値として $\boldsymbol{\theta}=\boldsymbol{0}$ を用い,
その他の変数は中立的な初期値から開始する.後続の実験では,DFL-CF に基づく初期化も導入し,初期化の影響を検証する.

\setcounter{savedtocdepth}{\value{tocdepth}}
\setcounter{tocdepth}{2}

%========================
% 実験結果
%========================
\section{実験結果}
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

%========================
% 実データによるベースライン比較
%========================
\subsection{実データによるベースライン比較}

本節では，第3章で導出した提案手法である DFL-OPT-K について，
実データを用いた比較手法との結果を示す．
以降の数値実験では，DFL-OPT-K を主たる提案手法として扱い，
下位問題の初期解には解析解に基づく DFL-CF を用いる．まず，図\ref{fig:baseline_cumreturn}に，
2006年1月から2025年12月までの全期間における各手法の累積資産推移を示す．

\begin{figure}[H]
\centering
\includegraphics[width=0.95\linewidth]{figs/baseline_cum_return.png}
\caption{累積資産推移}
\label{fig:baseline_cumreturn}
\end{figure}

図\ref{fig:baseline_cumreturn}より，DFL-OPT-K は比較手法と比べて，長期運用期間を通じて相対的に安定した資産成長を示していることが確認できる．
特に，大きな下落局面においても資産の毀損が抑制されており，時系列的に見て過度な変動を伴わない挙動が観察される．
\par
次に，表\ref{tab:baseline_summary}に主要な評価指標をまとめる．（太字:1位, 下線:2位. 提案手法は網掛け.）DFL-OPT-K は Sharpe 比，最終資産および年率リターンにおいて最も高い値を示しており，
年率ボラティリティや CVaR$_{95}$ といったリスク指標においても，等分散投資に次ぐ水準に留まっている．
これらの結果は，図\ref{fig:baseline_cumreturn}で観察された安定した資産推移が，リターン水準とリスク指標の双方において定量的にも裏付けられていることを示している．

\begin{table}[H]
\centering
\caption{評価指標の比較}
\label{tab:baseline_summary}
\small
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lrrrrrr}
\hline
Model & Sharpe & Terminal & Ann.\ Return & Ann.\ Vol & CVaR$_{95}$ \\
\hline
\rowcolor{gray!10}
DFL-OPT-K     & \textbf{0.81} & \textbf{9.14} & \textbf{12.27} & \underline{15.16} & \underline{4.94} \\
DFL-CF        & 0.61          & 6.07          & 10.57          & 17.36          & 5.65 \\
IPO-GRAD      & \underline{0.71} & \underline{8.42} & \underline{12.19} & 17.23          & 5.47 \\
SPO+          & 0.60          & 6.07          & 10.66          & 17.91          & 5.73 \\
PFL           & 0.34          & 2.49          &  6.42          & 19.04          & 6.68 \\
Buy\&Hold     & 0.57          & 5.64          & 10.35          & 18.14          & 6.19 \\
1/N           & 0.62          & 3.64          &  7.13          & \textbf{11.42} & \textbf{3.65} \\
\hline
\end{tabular}
\end{table}

以上より，DFL-OPT-K は実データにおいて，
既存手法と比較して競争力のある投資性能を示していることが確認できる．
次節以降では，
DFL-OPT-K の数値的性質や探索挙動に焦点を当て，
初期解の役割や最適化過程の安定性について詳細に検討する．

%========================
% 探索経路制御の効果
%========================
\subsection{探索経路制御の効果}
\par
本節では，提案手法 DFL-OPT-K において，探索経路の制御が数値的安定性および意思決定品質に与える影響を検証する．
第3章で述べたとおり，DFL-OPT-K は非凸な最適化問題を含むため，初期化や正則化といった探索経路の設計が，
収束挙動および得られる解の安定性に影響を与える可能性がある．
ここでは，解析解に基づく初期解の導入およびパラメータに対する罰則項の付加という二つの探索経路制御手法に着目する．

\subsubsection*{正則化強度 $\eta$ の選択}
\par
$\theta$ が解析解 $\theta_{\mathrm{CF}}$ から過度に乖離することを防ぐため，
本研究では目的関数に $\ell_2$ 型の罰則項
$\eta \lVert \theta - \theta_{\mathrm{CF}} \rVert_2^2$
を導入する．
正則化強度 $\eta$ は，データ全体（2006/01/01--2025/12/31）を
前半 10 年（2006/01/01--2015/12/31）と後半 10 年（2016/01/01--2025/12/31）に分割し，
前半期間のみを用いて選択した．
後半期間は，最終的な性能評価のために保持し，$\eta$ の選択には一切用いていない．

\par
前半 10 年の検証では，時系列の順序を保つため，学習期間を過去から順次延長し，
将来側の区間を検証に用いるホールドアウト検証を行った．
具体的には，学習期間を 2006 年から段階的に拡張し，
各段階でそれ以降の期間を検証区間とする複数の分割
（例：2006--2007 を学習，2008--2015 を検証；$\ldots$；2006--2012 を学習，2013--2015 を検証）を構成した．
各分割において，候補集合
$\eta \in \{0, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500\}$
に対する検証性能を算出し，分割間で集計した指標に基づいて比較を行った．

\par
$\eta$ の選択基準としては，検証区間における Sharpe 比の平均値を主指標とし，
同程度の Sharpe 比を示す候補が複数存在する場合には，
下方リスクの観点から CVaR$_{95}$ が小さいものを優先した．
その結果，$\eta=5$ が前半期間の検証において最も安定して良好な性能を示したため，
以降の実験ではこの値を採用する．

\par
\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.49\linewidth}
\centering
\includegraphics[width=\linewidth]{figs/lambda_tuning_sharpe_boxplot.png}
\caption{Sharpe 比}
\label{fig:lambda_tuning_sharpe_boxplot}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.49\linewidth}
\centering
\includegraphics[width=\linewidth]{figs/lambda_tuning_cvar95_boxplot.png}
\caption{CVaR$_{95}$}
\label{fig:lambda_tuning_cvar95_boxplot}
\end{subfigure}
\caption{検証期間における正則化強度ごとの性能分布}
\label{fig:lambda_tuning_boxplots}
\end{figure}

\subsubsection*{投資成績への影響}
\par
最後に，探索経路制御が実際の投資成績に与える影響を確認する．
ここでは，初期解および罰則項を導入した DFL-OPT-K を用いて，
時系列ホールドアウトの評価期間（2016/01/01--2025/12/31）における運用結果を確認する．
評価指標は取引コストを考慮した実行ベースの損益系列に基づいて算出する．
\par
\par
\begin{figure}[H]
\centering
\includegraphics[width=0.95\linewidth]{figs/holdout_cum_wealth_2016_2025.png}
\caption{ホールドアウト期間における累積資産推移}
\label{fig:holdout_cum_wealth_2016_2025}
\end{figure}
\par
\par
図\ref{fig:holdout_cum_wealth_2016_2025}に示す通り，
解析解初期化＋罰則項はホールドアウト期間において
他の設定と比較して安定した資産成長を示している．
実際，Sharpe 比は
初期化（$\theta=0$）（0.59），
解析解初期化（0.61）に対し，
解析解初期化＋罰則項では 0.67 と最も高い値を示した．
\par
\par
これらの結果から，
探索経路制御は数値的安定性を向上させるだけでなく，
投資成績を大きく損なうことなく，
場合によってはリスク調整後指標の改善にも寄与していることが確認できる．

%========================
% 提案手法の性質分析
%========================
\subsection{提案手法の性質分析}
\par
本節では，前節までで示した提案手法（DFL-OPT-K）の実証的な性能差が，どのような性質に起因しているのかを詳しく分析する．
特に本研究では，「予測精度の高さ」そのものではなく，「予測誤差を含んだ状況下で，どのような意思決定が行われているか」という観点から，提案手法の挙動を整理する．
\par
以下では，(i) 予測精度と意思決定品質の乖離，(ii) 問題条件の難易度（条件数）に応じた挙動の変化，(iii) ポートフォリオ解 $\boldsymbol{w}$ の構造的特徴，
および (iv) 危機局面における挙動，の順に検討する．

\subsubsection{予測精度と意思決定品質の乖離}
\par
まず，予測モデルの精度と，それに基づく投資成果との関係を確認する．


\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figs/r2_vs_sharpe_scatter.png}
  \caption{$R^2$ と Sharpe 比}
  \label{fig:r2_vs_sharpe}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figs/r2_vs_cvar_scatter.png}
  \caption{$R^2$ と CVaR$_{95}$}
  \label{fig:r2_vs_cvar95}
\end{subfigure}
\caption{決定係数 $R^2$ と意思決定品質の関係}
\label{fig:r2_vs_decision_quality}
\end{figure}

\par
図\ref{fig:r2_vs_decision_quality}は，各手法について，予測精度（決定係数 $R^2$）と意思決定品質（投資成績）との関係を示したものである．
\par
これらの図から，予測精度が必ずしも高い手法が高い Sharpe 比や低い CVaR を達成しているわけではないことが確認できる．
特に，PFL 系手法では比較的高い予測精度を示す場合であっても，投資成績が必ずしも改善されないケースが見られる．
\par
一方，提案手法 DFL-OPT-K は，予測精度が中程度である場合でも，相対的に高い Sharpe 比や良好な下方リスク指標を示している．
これは，提案手法が予測誤差を含んだ状況においても，最終的な意思決定を重視した学習・最適化を行っていることを示唆している．

\subsubsection{条件数レジーム別の比較分析}
\par
次に，下位最適化問題の数値的な難易度が，意思決定の品質にどのような影響を与えるかを分析する．
本研究では，各時点における共分散行列の条件数に基づき，市場環境を「低・中・高」の3つの条件数レジームに分類する．

\begin{table}[H]
\centering
\caption{条件数レジーム別: 意思決定誤差と有効資産数 $N_{\mathrm{eff}}$}
\label{tab:cond_regime_decision_error_neff}
{\footnotesize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{lrrrr|rrrr|rrrr}
\hline
 & \multicolumn{4}{c|}{低（条件数）} & \multicolumn{4}{c|}{中（条件数）} & \multicolumn{4}{c}{高（条件数）} \\
\cline{2-13}
Model & 平均 & p90 & p95 & $N_{\mathrm{eff}}$ & 平均 & p90 & p95 & $N_{\mathrm{eff}}$ & 平均 & p90 & p95 & $N_{\mathrm{eff}}$ \\
\hline
\rowcolor{gray!10}
DFL-OPT-K & 84.91 & \textbf{201.1} & \textbf{249.1} & \textbf{1.420} & \textbf{94.60} & \textbf{217.6} & \textbf{286.4} & \textbf{1.482} & 120.9 & \textbf{263.7} & \textbf{360.7} & \textbf{1.530} \\
DFL-CF    & \textbf{83.56} & 223.7 & 256.7 & 1.062 & 100.1 & 258.6 & 348.2 & 1.059 & 122.9 & 309.9 & 405.7 & 1.049 \\
IPO-GRAD  & \underline{83.98} & \underline{212.7} & \underline{255.6} & 1.038 & \underline{98.92} & \underline{243.9} & 330.6 & 1.070 & \underline{120.6} & \underline{293.2} & \underline{392.2} & 1.066 \\
SPO+      & 85.08 & 218.2 & 256.2 & 1.036 & 101.6 & 258.2 & \underline{310.6} & 1.049 & \textbf{119.7} & 320.7 & 410.9 & 1.071 \\
PFL       & 85.48 & 218.2 & 263.9 & \underline{1.079} & 101.1 & \underline{257.5} & 336.0 & \underline{1.101} & 132.0 & 329.1 & 481.3 & \underline{1.106} \\
\hline
\end{tabular}
}
\end{table}

\par
表\ref{tab:cond_regime_decision_error_neff}には，
各レジームにおける意思決定誤差および有効資産数 $N_{\mathrm{eff}}$をまとめている．
\par
この結果から，条件数が高くなるにつれて，多くの比較手法では意思決定誤差が大きくなり，有効資産数が急激に減少する傾向が確認される．
特に，条件数が高いレジームでは，解が一部の資産に極端に集中する傾向が顕著である．
\par
一方，提案手法 DFL-OPT-K は，高条件数レジームにおいても意思決定誤差の増大が相対的に抑制されており，有効資産数も安定して維持されている．
これは，提案手法が数値的に不安定な状況においても，意思決定を過度に歪めない構造を持っていることを示唆する．

\par
この挙動は，制約付き凸二次計画問題における最適解が，
アクティブ制約集合に応じた \emph{piecewise affine} な構造を持つことと整合的である．
すなわち，共分散行列の条件数が高い局面では，
わずかな予測誤差や数値誤差がアクティブ集合の切り替えを誘発し，
解が一部の資産に極端に集中するレジームへ遷移しやすい．
提案手法 DFL-OPT-K では，
このようなレジーム切り替えが相対的に抑制されている可能性が示唆される．
さらに，このような高条件数レジームにおける意思決定誤差の tail 抑制は，実際の投資成果にも部分的に反映されている．
表4.2に示すように，高条件数レジームでは多くの手法で意思決定誤差（平均・tail）が増大する一方，提案手法 DFL-OPT-K は p90/p95 の観点で相対的に小さい値を示しており，数値的に不安定な局面において極端な意思決定の失敗を回避しやすい可能性が示唆される．


\subsubsection{ポートフォリオ解 $\boldsymbol{w}$ の構造的特徴}
\par
前節では，共分散行列の条件数に応じて，
意思決定誤差や解の安定性が大きく変化することを確認した．
本節では，そのような数値的特性の違いが，
実際にどのようなポートフォリオ構造として現れているかを分析する．


\begin{table}[H]
\centering
\caption{ポートフォリオ構造の要約（太字:1位, 下線:2位. 提案手法は網掛け.）}
\label{tab:portfolio_structure_summary}
\footnotesize
\setlength{\tabcolsep}{5pt}
\begin{tabular}{lrrrrr}
\hline
Model & HHI（平均） & $P(\max_i w_i \ge 0.95)$ & 捕捉率（\%） & 平均ターンオーバー（\%） & 平均 $N_{\mathrm{eff}}$ \\
\hline
\rowcolor{gray!10}
DFL-OPT-K & \textbf{0.772} & \textbf{0.490} & \textbf{43.1} & 24.01 & \textbf{1.477} \\
DFL-CF    & 0.968 & 0.915 & 27.2 & 24.17 & 1.057 \\
IPO-GRAD  & 0.967 & 0.912 & 27.3 & 25.24 & 1.058 \\
SPO+      & 0.970 & 0.915 & 30.1 & \underline{21.02} & 1.052 \\
PFL       & \underline{0.947} & \underline{0.866} & \underline{30.6} & \textbf{20.73} & \underline{1.095} \\
\hline
\end{tabular}
\end{table}
\par
表\ref{tab:portfolio_structure_summary}には，各手法について，以下をまとめている．

\par
\begin{itemize}
  \item 平均ウェイト
  \item $P(\max_i w_i \ge 0.95)$（極端集中の発生確率）
  \item 週次リターン最大資産の捕捉率
  \item 平均ターンオーバーおよびスイッチ頻度
\end{itemize}
\par
この結果から，PFL 系手法では，
特定の資産への極端な集中や高頻度なポジション切替が生じやすいことが確認される．
これは，意思決定問題の解が，
異なるアクティブ集合に対応するレジーム間を頻繁に行き来している可能性を示唆する．
これに対し，提案手法 DFL-OPT-K は，
極端な集中の発生確率を低く抑えつつ，
必要な局面では資産配分を調整するという，
より滑らかなポートフォリオ更新を行っている．
\par
このような構造的特徴は，前節で確認した下方リスクの抑制や，安定した Sharpe 比の達成と整合的である．

\subsubsection{危機局面における挙動}
\par
最後に，市場の急変動が生じた危機局面における挙動を検証する．
本研究では，リーマンショック期，COVID-19 初期局面，およびインフレ局面を代表的な危機局面として取り上げる．
\par

\begin{table}[H]
\centering
\caption{危機局面における性能指標（太字:1位, 下線:2位. 提案手法は網掛け.）}
\label{tab:crisis_event_metrics}
\footnotesize
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lrr|rr|rr}
\hline
 & \multicolumn{2}{c|}{リーマン危機} & \multicolumn{2}{c|}{コロナショック} & \multicolumn{2}{c}{インフレ局面} \\
\cline{2-7}
Model & Sharpe & CVaR$_{95}$ & Sharpe & CVaR$_{95}$ & Sharpe & CVaR$_{95}$ \\
\hline
\rowcolor{gray!10}
DFL-OPT-K & 0.238          & \textbf{6.87} & \textbf{1.047} & \textbf{8.13} & \textbf{0.615} & \textbf{3.89} \\
DFL-CF    & \textbf{0.493} & \underline{7.42}          & \underline{0.996}          & \underline{9.42}          & $-$0.200       & \underline{4.51} \\
IPO-GRAD  & $-$0.168       & 9.76          & $-$0.210       & 12.11         & 0.021          & 4.76 \\
SPO+      & \underline{0.249}          & 7.77          & 0.010          & 11.32         & \underline{0.123}          & 4.85 \\
PFL       & $-$0.385       & 9.88          & $-$0.291       & 12.06         & $-$0.402       & 4.91 \\
\hline
\end{tabular}
\end{table}

\par
ここには，各局面における Sharpe 比，下方リスク指標（CVaR または MaxDD），およびターンオーバーをまとめている．
\par
危機局面において，提案手法は相対的に下方リスクを抑制しつつ，過度な取引を伴わない安定した挙動を示している．
特に，急激な市場下落局面においても，ポートフォリオが極端な集中状態に陥ることを回避している点が特徴的である．

%========================
% 第5章：結論
%========================
\chapter{結論}
\par
本章では,本研究で得られた知見を総括する.方法論的には,制約付き平均--分散ポートフォリオ最適化を下位問題として含む DFL を悲観的二段階最適化として定式化し,
下位問題の最適性条件に基づく2つの単一レベル再定式化（DFL-OPT-D,DFL-OPT-K）を導出した.また,理論的同値性と数値計算上の挙動が必ずしも一致しない点を,
実データ実験で検証可能な形で整理した.実証的には,週次TAAの実データ実験において,提案手法（DFL-OPT-K）が $R^2$ の向上に依らずに, 
Sharpe 比の改善や CVaR$_{95}$ の低下を通じて意思決定品質を向上させ得ることを示した.
改善は平均だけでなく分布の裾（p90/p99）の抑制としても現れ,条件数が高い局面で相対的に下方リスクを抑える傾向が確認された.
また,この改善は売買量や切替頻度の増加だけでは説明されにくく,COVID-19 局面では安全資産（TLT）への動的シフトが観察された.
今後は,非凸性に伴う局所解・初期化依存の低減,多資産化と現実的制約の導入,および感度分析や解法安定化を通じた実務適用可能性の検証を進める.

%========================
% 謝辞
%========================
\newpage
\chapter*{謝辞}
\addcontentsline{toc}{chapter}{謝辞}
本研究をご指導くださった高野祐一准教授をはじめ,議論に協力してくださった研究室の皆様に深く感謝いたします.

%========================
% 参考文献
%========================
\newpage
\bibliographystyle{jplain}
\bibliography{cite}

%========================
% Appendix
%========================
\newpage
\appendix
\chapter*{Appendix}
\addcontentsline{toc}{chapter}{Appendix}
\section*{A. 命題 \ref{prop:equivalence} の証明}
\addcontentsline{toc}{section}{A. 命題 \ref{prop:equivalence} の証明}
\par
本章では,DFL-OPT-D と DFL-OPT-K が理論的に同値であることを示す.
\begin{proof}
各 $i=1,\dots,T$ に対して,下位のポートフォリオ最適化問題 \eqref{eq:lower_level_recall} は目的関数が強凸な二次関数であり,
等式制約および非負制約からなる凸制約集合を持つ凸二次計画問題である.また,$\boldsymbol{w}_i>\boldsymbol{0}$ かつ $\boldsymbol{1}^\top\boldsymbol{w}_i=1$ を満たす
内点が存在するため,Slater 条件が成り立つ.したがって,強双対性が成立する.
\par
強双対性の成立より,下位問題の最適解は KKT 条件を満たす点と必要十分に一致する.すなわち,ある双対変数 $(\mu_i,\boldsymbol{\lambda}_i)$ が存在して,停留条件
\[
\delta \boldsymbol{V}_i \boldsymbol{w}_i-(1-\delta)\hat{\boldsymbol{r}}_i-\mu_i\boldsymbol{1}-\boldsymbol{\lambda}_i=\boldsymbol{0},
\]
主問題の可行性
\[
\boldsymbol{1}^\top\boldsymbol{w}_i=1,\quad \boldsymbol{w}_i\ge\boldsymbol{0},
\]
双対可行性
\[
\boldsymbol{\lambda}_i\ge\boldsymbol{0},
\]
および相補性条件
\[
\boldsymbol{\lambda}_i\odot\boldsymbol{w}_i=\boldsymbol{0}
\]
が同時に成り立つとき, $\boldsymbol{w}_i$ は下位問題の最適解である.
\par
DFL-OPT-K は,上記の KKT 条件を制約として直接組み込んだ定式化である.一方,DFL-OPT-D は,主問題の可行性と双対可行性に加え,
停留条件 \eqref{eq:dfl_dual_stationarity} と最適値一致条件 \eqref{eq:dfl_dual_value} を課すことで下位問題の最適性を表現している.
強双対性が成立する凸最適化問題においては,これらの条件は KKT 条件と同値であるため,DFL-OPT-D により許容される $(\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i)$ の集合は,
DFL-OPT-K により許容される集合と一致する.
\par
以上より,DFL-OPT-D（\eqref{eq:dfl_dual_obj}--\eqref{eq:dfl_dual_stationarity}）と 
DFL-OPT-K（\eqref{eq:dfl_kkt_obj}--\eqref{eq:dfl_kkt_complementarity}）は同一の解集合を持ち,理論的に等価であることが示された.
\end{proof}

\section*{B. DFL-OPT-D における強双対性制約の導出}
\addcontentsline{toc}{section}{B. DFL-OPT-D における強双対性制約の導出}
\par
ここでは,本文 \eqref{eq:dfl_dual_value} および \eqref{eq:dual_strong_simplified}（したがって \eqref{eq:dfl_dual_value}）の導出を,双対関数 $g_i$ の導出を含めて示す.
\par
まず,ラグランジュ関数 \eqref{eq:lagrangian} に基づき,双対関数を
\[
g_i(\mu_i,\boldsymbol{\lambda}_i)
:=\inf_{\boldsymbol{w}_i\in\mathbb{R}^d}\mathcal{L}_i(\boldsymbol{w}_i,\mu_i,\boldsymbol{\lambda}_i)
\]
と定義する.ここで $\mathcal{L}_i$ を $\boldsymbol{w}_i$ で最小化する停留条件は本文 \eqref{eq:dfl_dual_stationarity} であり,これより
\[
\tilde{\boldsymbol{w}}_i(\mu_i,\boldsymbol{\lambda}_i)
=\frac{1}{\delta}\boldsymbol{V}_i^{-1}\!\left((1-\delta)\hat{\boldsymbol{r}}_i+\mu_i\boldsymbol{1}+\boldsymbol{\lambda}_i\right)
\]
を得る.これを代入すると,双対関数は
\[
g_i(\mu_i,\boldsymbol{\lambda}_i)
=\mu_i-\frac{1}{2\delta}
\left((1-\delta)\hat{\boldsymbol{r}}_i+\mu_i\boldsymbol{1}+\boldsymbol{\lambda}_i\right)^\top
\boldsymbol{V}_i^{-1}
\left((1-\delta)\hat{\boldsymbol{r}}_i+\mu_i\boldsymbol{1}+\boldsymbol{\lambda}_i\right)
\]
と表される.
\par
次に,停留条件 \eqref{eq:dfl_dual_stationarity} を
\[
\delta \boldsymbol{V}_i \boldsymbol{w}_i=(1-\delta)\hat{\boldsymbol{r}}_i+\mu_i\boldsymbol{1}+\boldsymbol{\lambda}_i
\]
と書き直し,右辺を $z_i$ とおくと $z_i=\delta \boldsymbol{V}_i\boldsymbol{w}_i$ である.これを上式に代入すると
\[
g_i(\mu_i,\boldsymbol{\lambda}_i)
=\mu_i-\frac{1}{2\delta}(\delta \boldsymbol{V}_i\boldsymbol{w}_i)^\top \boldsymbol{V}_i^{-1}(\delta \boldsymbol{V}_i\boldsymbol{w}_i)
=\mu_i-\frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\]
となり,双対目的値は停留条件を介して $V_i^{-1}$ を含まない形に簡約できる.
\par
弱双対性より,任意の主問題の実行可能解 $\boldsymbol{w}_i$ と双対変数 $(\mu_i,\boldsymbol{\lambda}_i)$（$\boldsymbol{\lambda}_i\ge\boldsymbol{0}$）に対して,
主問題目的値は双対目的値の上界である.したがって,
\[
-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
+\frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\ge
\mu_i-\frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i
\]
が成り立つ.これが本文 \eqref{eq:dfl_dual_value} である.両辺に $\frac{\delta}{2}\boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i$ を加えると
\[
\delta \boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
\ge \mu_i
\]
を得る.
\par
最後に,強双対性より最適解においては弱双対性の不等式が等号で成立する.このとき KKT 条件の相補性 $\boldsymbol{\lambda}_i\odot\boldsymbol{w}_i=\boldsymbol{0}$ が成り立ち,
導出中に現れる $\boldsymbol{\lambda}_i^\top\boldsymbol{w}_i$ が消えるため,最適値一致条件は
\[
\delta \boldsymbol{w}_i^\top \boldsymbol{V}_i \boldsymbol{w}_i-(1-\delta)\hat{\boldsymbol{r}}_i^\top \boldsymbol{w}_i
= \mu_i
\]
と表される.これが本文 \eqref{eq:dual_strong_simplified} の等式であり,
DFL-OPT-D では各 $i$ についてこの関係を制約 \eqref{eq:dfl_dual_value} として課している.

\section*{C. OAS 縮小係数と実効サンプルサイズ}
\addcontentsline{toc}{section}{C. OAS 縮小係数と実効サンプルサイズ}
\par
ここでは,第4章で用いた OAS の縮小係数 $\phi_t$ と,EWMA の重みに対応する実効サンプルサイズ $n_{\mathrm{eff}}$ の具体式を示す.
\par
まず,$d$ 次元の共分散推定に用いるサンプルサイズを $n_{\mathrm{eff}}$ とすると,OAS による縮小係数は
\begin{equation}
\phi_t
= \min\left\{
1,\ 
\frac{\left(1-\frac{2}{d}\right)\mathrm{tr}(\boldsymbol{S}_t^2)+\mathrm{tr}(\boldsymbol{S}_t)^2}
{\left(n_{\mathrm{eff}}+1-\frac{2}{d}\right)\left(\mathrm{tr}(\boldsymbol{S}_t^2)-\frac{\mathrm{tr}(\boldsymbol{S}_t)^2}{d}\right)}
\right\}
\tag{A.1}
\end{equation}
で与えられる.
\par
次に,EWMA における減衰率 $\alpha$ は,重み付き標本に基づく共分散推定の「記憶長」を制御するパラメータとして解釈できる \cite{jpm2006riskmetrics}.
特に,重み $w_k=(1-\alpha)\alpha^k$ に対して定義される実効サンプルサイズ
\[
\mathrm{ESS}:=\frac{1}{\sum_k w_k^2}
\]
を用いると,EWMA はおよそ $\mathrm{ESS}\approx \frac{1+\alpha}{1-\alpha}$ 個の独立標本に
相当する情報量を持つと解釈できる \cite{jpm2006riskmetrics}.
本研究ではこの対応関係に基づき,短期ローリング設定における数値的安定性と反応性のバランスを考慮して $\alpha$ を設定する.
\par
本研究のように有限窓 $L$ を用いるとき,重みを正規化した $\tilde{w}_k := \frac{(1-\alpha)\alpha^k}{1-\alpha^L}$（$k=0,\dots,L-1$）に対して
\begin{equation}
n_{\mathrm{eff}}
:= \frac{1}{\sum_{k=0}^{L-1}\tilde{w}_k^2}
= \frac{(1-\alpha^L)^2}{(1-\alpha)^2}\cdot\frac{1-\alpha^2}{1-\alpha^{2L}}
= \frac{1+\alpha}{1-\alpha}\cdot\frac{(1-\alpha^L)^2}{1-\alpha^{2L}}
\tag{A.2}
\end{equation}
となる.特に $L$ が十分大きい場合には $n_{\mathrm{eff}} \approx \frac{1+\alpha}{1-\alpha}$ となり,上の $\mathrm{ESS}$ の近似と整合する.

\section*{D. 初期解＋罰則項あり（全期間）の参考結果}
\addcontentsline{toc}{section}{D. 初期解＋罰則項あり（全期間）の参考結果}
\par
本付録では,初期解＋罰則項を導入した場合について,
取引コストを控除した実行ベースの損益系列に基づく全期間（2006--2025）の累積資産推移を参考として示す．
なお,本結果は提案手法の主張を補強するものではなく,
探索経路制御が実務的なコストを考慮しても致命的な性能劣化を招かないことを確認する目的で提示する．
\par
本実験では,ティッカー別の取引コスト（bps）を
``SPY:5, GLD:10, EEM:10, TLT:5''
として設定した（デフォルト設定）．

\begin{figure}[H]
\centering
\includegraphics[width=0.95\linewidth]{figs/appendix_fullperiod_wealth_penalty.png}
\caption{全期間（2006--2025）における累積資産推移（初期解＋罰則項, 取引コスト控除後）}
\label{fig:appendix_fullperiod_wealth_penalty}
\end{figure}

\begin{table}[H]
\centering
\caption{全期間（2006--2025）における性能指標（初期解＋罰則項, 取引コスト控除後；参考，太字:1位, 下線:2位. 提案手法は網掛け.）}
\label{tab:appendix_fullperiod_summary_cost}
\footnotesize
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lrrrrr}
\hline
Model & 年率リターン(\%) & 最終資産 & Sharpe 比 & 年率ボラ(\%) & CVaR$_{95}$(\%) \\
\hline
\rowcolor{gray!10}
DFL-OPT-K & \textbf{13.95} & \textbf{12.15} & \textbf{0.83} & \underline{16.76} & \underline{$-$5.21} \\
DFL-CF & 9.66 & 5.07 & 0.56 & 17.36 & $-$5.65 \\
IPO-GRAD & 9.85 & 5.25 & 0.57 & 17.39 & $-$5.63 \\
SPO+ & 9.50 & 4.90 & 0.55 & 17.38 & $-$5.67 \\
PFL & 5.61 & 2.11 & 0.29 & 19.04 & $-$6.68 \\
Buy\&Hold(SPY) & \underline{10.35} & \underline{5.64} & 0.57 & 18.14 & $-$6.19 \\
1/N & 7.13 & 3.64 & \underline{0.62} & \textbf{11.42} & \textbf{$-$3.65} \\
\hline
\end{tabular}
\end{table}

%========================
% Appendix E: 命題の導出
%========================
\section*{E. 命題 \ref{prop:local_sensitivity} の導出（アクティブ集合固定下）}
\addcontentsline{toc}{section}{E. 命題 \ref{prop:local_sensitivity} の導出（アクティブ集合固定下）}
\par
本節では，命題 \ref{prop:local_sensitivity} の導出を示す．
以下では簡単のため時点添字を省略し，
\eqref{eq:lower_qp_sensitivity} の下位問題
\[
\min_{\boldsymbol{w}}
\;f(\boldsymbol{w};\hat{\boldsymbol{r}},\boldsymbol{V})
:=
-(1-\delta)\hat{\boldsymbol{r}}^\top \boldsymbol{w}
+\frac{\delta}{2}\boldsymbol{w}^\top \boldsymbol{V}\boldsymbol{w}
\quad
\text{s.t.}\quad
\boldsymbol{1}^\top\boldsymbol{w}=1,\;\boldsymbol{w}\ge \boldsymbol{0}
\]
を考える．ここで $\delta>0$，$\boldsymbol{V}\succ\boldsymbol{0}$ とする．

\subsection*{E.1 アクティブ集合固定による縮約}
\par
最適解を $\boldsymbol{w}^*(\hat{\boldsymbol{r}},\boldsymbol{V})$ とし，
正の成分集合（アクティブ集合）を
\[
A:=\{j\in\{1,\dots,d\}\mid w_j^*>0\},\qquad N:=A^c
\]
とおく．
アクティブ集合が近傍で不変（すなわち $w_A^*>0$ かつ $w_N^*=0$ が近傍で維持される）と仮定する．
このとき，制約 $w\ge0$ は局所的に
\[
\boldsymbol{w}_N=\boldsymbol{0}
\]
という等式制約に置き換えられる．
したがって，局所的には次の縮約問題と同値になる：
\begin{equation}
\min_{\boldsymbol{w}_A\in\mathbb{R}^{|A|}}
\;-(1-\delta)\hat{\boldsymbol{r}}_A^\top \boldsymbol{w}_A
+\frac{\delta}{2}\boldsymbol{w}_A^\top \boldsymbol{V}_{AA}\boldsymbol{w}_A
\quad
\text{s.t.}\quad
\boldsymbol{1}_A^\top \boldsymbol{w}_A=1.
\label{eq:reduced_qp}
\end{equation}
ここで $\boldsymbol{1}_A$ は $|A|$ 次元の全成分 $1$ ベクトルである．
$\boldsymbol{V}\succ0$ より主小行列 $\boldsymbol{V}_{AA}\succ0$ であり，
\eqref{eq:reduced_qp} は強凸な等式制約付きQPである．

\subsection*{E.2 縮約問題のKKT条件}
\par
\eqref{eq:reduced_qp} のラグランジュ関数を
\[
\mathcal{L}(\boldsymbol{w}_A,\mu)
=
-(1-\delta)\hat{\boldsymbol{r}}_A^\top \boldsymbol{w}_A
+\frac{\delta}{2}\boldsymbol{w}_A^\top \boldsymbol{V}_{AA}\boldsymbol{w}_A
+\mu(1-\boldsymbol{1}_A^\top \boldsymbol{w}_A)
\]
とする．KKT 条件は
\begin{align}
\delta \boldsymbol{V}_{AA}\boldsymbol{w}_A - (1-\delta)\hat{\boldsymbol{r}}_A - \mu \boldsymbol{1}_A &= \boldsymbol{0},
\label{eq:kkt_reduced_stationarity}\\
\boldsymbol{1}_A^\top \boldsymbol{w}_A &= 1
\label{eq:kkt_reduced_budget}
\end{align}
である．
\eqref{eq:kkt_reduced_stationarity} より
\begin{equation}
\boldsymbol{w}_A
=
\frac{1}{\delta}\boldsymbol{V}_{AA}^{-1}
\bigl((1-\delta)\hat{\boldsymbol{r}}_A+\mu \boldsymbol{1}_A\bigr).
\label{eq:wA_mu}
\end{equation}
これを \eqref{eq:kkt_reduced_budget} に代入すると
\[
\boldsymbol{1}_A^\top \boldsymbol{w}_A
=
\frac{1}{\delta}\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}
\bigl((1-\delta)\hat{\boldsymbol{r}}_A+\mu \boldsymbol{1}_A\bigr)
=1,
\]
すなわち
\begin{equation}
\mu
=
\frac{\delta-(1-\delta)\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\hat{\boldsymbol{r}}_A}
{\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A}.
\label{eq:mu_closed}
\end{equation}
\eqref{eq:mu_closed} を \eqref{eq:wA_mu} に代入すると
\[
\boldsymbol{w}_A^*(\hat{\boldsymbol{r}}_A,\boldsymbol{V}_{AA})
=
\underbrace{\frac{1-\delta}{\delta}\boldsymbol{V}_{AA}^{-1}\hat{\boldsymbol{r}}_A}_{\text{線形項}}
+
\underbrace{\frac{1}{\delta}\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A\,
\frac{\delta-(1-\delta)\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\hat{\boldsymbol{r}}_A}
{\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A}}_{\text{アフィン補正}}
\]
を得る．よって $\boldsymbol{w}_A^*$ は $\hat{\boldsymbol{r}}_A$ に関して affine である．

\subsection*{E.3 ヤコビアンの導出（式 \eqref{eq:jacobian_affine}）}
\par
\eqref{eq:wA_mu} を $\hat{\boldsymbol{r}}_A$ で微分すると
\[
\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}
=
\frac{1-\delta}{\delta}\boldsymbol{V}_{AA}^{-1}
+
\frac{1}{\delta}\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A
\frac{\partial \mu}{\partial \hat{\boldsymbol{r}}_A}.
\]
一方，\eqref{eq:mu_closed} より
\[
\mu
=
\frac{\delta}{\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A}
-
\frac{1-\delta}{\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A}
\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\hat{\boldsymbol{r}}_A
\]
なので
\[
\frac{\partial \mu}{\partial \hat{\boldsymbol{r}}_A}
=
-\frac{1-\delta}{\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A}
\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}.
\]
したがって
\begin{align}
\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}
&=
\frac{1-\delta}{\delta}\boldsymbol{V}_{AA}^{-1}
-
\frac{1-\delta}{\delta}
\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A
(\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A)^{-1}
\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1},
\label{eq:jacobian_affine}
\end{align}
すなわち本文 \eqref{eq:jacobian_affine} を得る．

\subsection*{E.4 局所Lipschitz上界（式 \eqref{eq:lipschitz_bound}）}
\par
同一アクティブ集合 $A$ が維持される局所では
\[
\Delta \boldsymbol{w}_A^*
=
\left(\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}\right)\Delta\hat{\boldsymbol{r}}_A
\]
が成り立つため，
\[
\|\Delta \boldsymbol{w}_A^*\|_2
\le
\left\|
\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}
\right\|_2
\|\Delta \hat{\boldsymbol{r}}_A\|_2
\]
である．
ここで
\[
\boldsymbol{P}_A
:=
\boldsymbol{I}
-
\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A
(\boldsymbol{1}_A^\top\boldsymbol{V}_{AA}^{-1}\boldsymbol{1}_A)^{-1}
\boldsymbol{1}_A^\top
\]
とおくと，
\[
\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}
=
\frac{1-\delta}{\delta}
\boldsymbol{P}_A\boldsymbol{V}_{AA}^{-1}.
\]
よって
\[
\left\|
\frac{\partial \boldsymbol{w}_A^*}{\partial \hat{\boldsymbol{r}}_A}
\right\|_2
\le
\frac{1-\delta}{\delta}\,
\|\boldsymbol{P}_A\|_2\,
\|\boldsymbol{V}_{AA}^{-1}\|_2
=
\frac{1-\delta}{\delta}\,
\|\boldsymbol{P}_A\|_2\,
\frac{1}{\lambda_{\min}(\boldsymbol{V}_{AA})}.
\]
これより
\begin{equation}
\|\Delta \boldsymbol{w}_A^*\|_2
\le
C_A\,
\frac{1-\delta}{\delta}\,
\frac{1}{\lambda_{\min}(\boldsymbol{V}_{AA})}\,
\|\Delta \hat{\boldsymbol{r}}_A\|_2
\label{eq:lipschitz_bound}
\end{equation}
が得られる．ただし $C_A:=\|\boldsymbol{P}_A\|_2<\infty$ とおいた．
最後に $\Delta \boldsymbol{w}^*$ は $N$ 成分がゼロのままなので，
$\|\Delta \boldsymbol{w}^*\|_2=\|\Delta \boldsymbol{w}_A^*\|_2$ が成り立ち，
本文の \eqref{eq:lipschitz_bound} が従う．
\par
以上で命題 \ref{prop:local_sensitivity} の導出を完了する．

\par
\noindent\textbf{注記（局所性）}：
本節の導出は，ある最適解近傍でアクティブ集合 $A$ が不変である局所に限定している．
境界（$w_j^*=0$ に接する点）では集合が切り替わり得るため，写像は一般に大域的には滑らかでない．
\end{document}
